{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Project 1 - Phenotypic Prediction from Transcriptomic Features\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cPickle as pkl\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "import utilities\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Extracted the TPM value for each Accession folder and stored in the 'tpm_train.pkl' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"tpm_train_with_eqc.pkl\", 'rb') as input_file:\n",
    "    data = pkl.load(input_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)    \n",
    "data.set_index(0, inplace=True)\n",
    "\n",
    "labels = data.iloc[:,-2:]\n",
    "\n",
    "data.columns = [str(i) for i in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.drop(['199327','199328'], axis=1)\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    369.000000\n",
       "mean      80.707268\n",
       "std       17.161161\n",
       "min       33.948341\n",
       "25%       69.099884\n",
       "50%       79.788773\n",
       "75%       91.965858\n",
       "max      166.347031\n",
       "Name: 199326, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['199326'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>199317</th>\n",
       "      <th>199318</th>\n",
       "      <th>199319</th>\n",
       "      <th>199320</th>\n",
       "      <th>199321</th>\n",
       "      <th>199322</th>\n",
       "      <th>199323</th>\n",
       "      <th>199324</th>\n",
       "      <th>199325</th>\n",
       "      <th>199326</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ERR188023</th>\n",
       "      <td>0.372590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.22841</td>\n",
       "      <td>0.375841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.953598</td>\n",
       "      <td>171.121994</td>\n",
       "      <td>2886.239990</td>\n",
       "      <td>6365.470215</td>\n",
       "      <td>227.203995</td>\n",
       "      <td>4590.790039</td>\n",
       "      <td>353.976990</td>\n",
       "      <td>1974.739990</td>\n",
       "      <td>4.998195</td>\n",
       "      <td>97.296394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR188022</th>\n",
       "      <td>0.797727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.58229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.684310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.211201</td>\n",
       "      <td>83.254097</td>\n",
       "      <td>3149.229980</td>\n",
       "      <td>6786.430176</td>\n",
       "      <td>88.995796</td>\n",
       "      <td>3629.209961</td>\n",
       "      <td>437.084015</td>\n",
       "      <td>2652.649902</td>\n",
       "      <td>4.922488</td>\n",
       "      <td>57.534142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR188356</th>\n",
       "      <td>0.090220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.51668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.274090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.431000</td>\n",
       "      <td>109.183998</td>\n",
       "      <td>3163.649902</td>\n",
       "      <td>9510.320312</td>\n",
       "      <td>121.857002</td>\n",
       "      <td>5556.990234</td>\n",
       "      <td>586.945007</td>\n",
       "      <td>2406.679932</td>\n",
       "      <td>5.065081</td>\n",
       "      <td>63.784302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR188079</th>\n",
       "      <td>0.220742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.80056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.131810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>229.815994</td>\n",
       "      <td>490.273987</td>\n",
       "      <td>1677.089966</td>\n",
       "      <td>3139.790039</td>\n",
       "      <td>274.553009</td>\n",
       "      <td>1913.510010</td>\n",
       "      <td>529.495972</td>\n",
       "      <td>3157.360107</td>\n",
       "      <td>4.875267</td>\n",
       "      <td>33.948341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR188032</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.41379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.936256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.686672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71.057800</td>\n",
       "      <td>163.998993</td>\n",
       "      <td>3299.810059</td>\n",
       "      <td>6968.649902</td>\n",
       "      <td>256.239014</td>\n",
       "      <td>3721.270020</td>\n",
       "      <td>521.898010</td>\n",
       "      <td>2534.120117</td>\n",
       "      <td>4.969185</td>\n",
       "      <td>81.912567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 199326 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1    2        3         4         5    6         7    8  \\\n",
       "0                                                                           \n",
       "ERR188023  0.372590  0.0  4.22841  0.375841  0.000000  0.0  0.000000  0.0   \n",
       "ERR188022  0.797727  0.0  4.58229  0.000000  0.000000  0.0  0.000000  0.0   \n",
       "ERR188356  0.090220  0.0  8.51668  0.000000  0.000000  0.0  0.000000  0.0   \n",
       "ERR188079  0.220742  0.0  3.80056  0.000000  0.000000  0.0  0.000000  0.0   \n",
       "ERR188032  0.000000  0.0  4.41379  0.000000  0.001128  0.0  0.936256  0.0   \n",
       "\n",
       "                  9   10    ...          199317      199318       199319  \\\n",
       "0                           ...                                            \n",
       "ERR188023  0.038324  0.0    ...       90.953598  171.121994  2886.239990   \n",
       "ERR188022  1.684310  0.0    ...       22.211201   83.254097  3149.229980   \n",
       "ERR188356  2.274090  0.0    ...       25.431000  109.183998  3163.649902   \n",
       "ERR188079  1.131810  0.0    ...      229.815994  490.273987  1677.089966   \n",
       "ERR188032  0.686672  0.0    ...       71.057800  163.998993  3299.810059   \n",
       "\n",
       "                199320      199321       199322      199323       199324  \\\n",
       "0                                                                          \n",
       "ERR188023  6365.470215  227.203995  4590.790039  353.976990  1974.739990   \n",
       "ERR188022  6786.430176   88.995796  3629.209961  437.084015  2652.649902   \n",
       "ERR188356  9510.320312  121.857002  5556.990234  586.945007  2406.679932   \n",
       "ERR188079  3139.790039  274.553009  1913.510010  529.495972  3157.360107   \n",
       "ERR188032  6968.649902  256.239014  3721.270020  521.898010  2534.120117   \n",
       "\n",
       "             199325     199326  \n",
       "0                               \n",
       "ERR188023  4.998195  97.296394  \n",
       "ERR188022  4.922488  57.534142  \n",
       "ERR188356  5.065081  63.784302  \n",
       "ERR188079  4.875267  33.948341  \n",
       "ERR188032  4.969185  81.912567  \n",
       "\n",
       "[5 rows x 199326 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>199325</th>\n",
       "      <th>199326</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ERR188023</th>\n",
       "      <td>FIN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR188022</th>\n",
       "      <td>CEU</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR188356</th>\n",
       "      <td>TSI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR188079</th>\n",
       "      <td>TSI</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR188032</th>\n",
       "      <td>CEU</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          199325 199326\n",
       "0                      \n",
       "ERR188023    FIN      2\n",
       "ERR188022    CEU      1\n",
       "ERR188356    TSI      1\n",
       "ERR188079    TSI      4\n",
       "ERR188032    CEU      7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Trying ExtraTreesClassifier on TPM for finding Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 93295 (0.000949)\n",
      "2. feature 70175 (0.000827)\n",
      "3. feature 29548 (0.000823)\n",
      "4. feature 163898 (0.000789)\n",
      "5. feature 5027 (0.000733)\n",
      "6. feature 127135 (0.000701)\n",
      "7. feature 168825 (0.000663)\n",
      "8. feature 161877 (0.000646)\n",
      "9. feature 157375 (0.000638)\n",
      "10. feature 34275 (0.000609)\n",
      "11. feature 168948 (0.000596)\n",
      "12. feature 160135 (0.000593)\n",
      "13. feature 120673 (0.000586)\n",
      "14. feature 76393 (0.000573)\n",
      "15. feature 175825 (0.000572)\n"
     ]
    }
   ],
   "source": [
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250, n_jobs=-1, bootstrap=True, oob_score=True, verbose=1,\n",
    "                              random_state=0)\n",
    "\n",
    "# using out-of-bag samples for testing generalization accuracy\n",
    "\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1])[:15]:\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8sAAAHoCAYAAAB+Vn0eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xu8bWVdL/7Pl70F7zfcmYK6UVDbevLSDrOXt6QCPSVW\nmpAVpsYvw5OXXyV0zAyPJVpZ3iqPomgakKbuysQLXlPR7TUR0S1goqigaKIGAc/5Y4wFk7HnXGus\nzbrv9/v1Wq815jOe+YzvGGOOy3eOMZ5ZrbUAAAAA19pntQMAAACAtUayDAAAAAOSZQAAABiQLAMA\nAMCAZBkAAAAGJMsAAAAwIFkGAACAAckyAAAADEiWAQAAYGDzagew1tzmNrdpW7duXe0wAAAAWAYf\n+9jHLmmtbVmonmR5YOvWrdm5c+dqhwEAAMAyqKovjannNmwAAAAYkCwDAADAgGQZAAAABiTLAAAA\nMCBZBgAAgAHJMgAAAAxIlgEAAGBAsgwAAAADkmUAAAAYkCwDAADAgGQZAAAABiTLAAAAMCBZBgAA\ngAHJMgAAAAxIlgEAAGBAsgwAAAADkmUAAAAYkCwDAADAgGQZAAAABjavdgB7parVjqDT2mpHAAAA\nsCa5sgwAAAADkmUAAAAYkCwDAADAgGQZAAAABiTLAAAAMCBZBgAAgAHJMgAAAAxIlgEAAGBAsgwA\nAAADkmUAAAAYkCwDAADAgGQZAAAABiTLAAAAMCBZBgAAgIEVT5ar6oiqOreqdlXV8VPG71dVp/Xj\nz6qqrRPjTujLz62qwyfKT66qb1TVZwZtvaCqPldVn66qN1XVLZdz3gAAANgYVjRZrqpNSV6a5GFJ\ntiU5uqq2Dao9IcmlrbWDk7wwyUn9e7clOSrJPZIckeRlfXtJ8uq+bOgdSe7ZWvvRJJ9PcsKSzhAA\nAAAb0kpfWT40ya7W2nmttSuSnJrkyEGdI5Oc0g+/IclhVVV9+amttctba+cn2dW3l9ba+5J8azix\n1trbW2tX9i8/nOTApZ4hAAAANp6VTpYPSPLlidcX9mVT6/SJ7neS7D/yvfN5fJJ/nTaiqo6tqp1V\ntfPiiy9eRJMAAABsRHtFB19V9b+TXJnkddPGt9Ze3lrb3lrbvmXLlpUNDgAAgDVnpZPlryS5w8Tr\nA/uyqXWqanOSWyT55sj37qaqHpfk55I8trXW9jRwAAAA9h4rnSx/NMkhVXVQVe2brsOuHYM6O5Ic\n0w8/KsmZfZK7I8lRfW/ZByU5JMlH5ptYVR2R5PeTPKK19v0lnA8AAAA2sBVNlvtnkJ+c5Iwk5yQ5\nvbV2dlWdWFWP6Ku9Msn+VbUrydOTHN+/9+wkpyf5bJK3JTmutXZVklTV3yf5UJK7VdWFVfWEvq2X\nJLlZkndU1Ser6m9WZEYBAABY18qdyde1ffv2tnPnzuWdSNXytj+WdQ8AAOxlqupjrbXtC9XbKzr4\nAgAAgMWQLAMAAMCAZBkAAAAGJMsAAAAwIFkGAACAAckyAAAADEiWAQAAYECyDAAAAAOSZQAAABiQ\nLAMAAMCAZBkAAAAGJMsAAAAwIFkGAACAAckyAAAADGxe7QBY46pWO4JOa6sdAQAAsBdxZRkAAAAG\nJMsAAAAwIFkGAACAAckyAAAADEiWAQAAYECyDAAAAAOSZQAAABiQLAMAAMCAZBkAAAAGJMsAAAAw\nIFkGAACAAckyAAAADEiWAQAAYECyDAAAAAOSZQAAABiQLAMAAMCAZBkAAAAGJMsAAAAwIFkGAACA\nAckyAAAADEiWAQAAYECyDAAAAAOSZQAAABiQLAMAAMCAZBkAAAAGJMsAAAAwIFkGAACAAckyAAAA\nDEiWAQAAYECyDAAAAAOSZQAAABiQLAMAAMCAZBkAAAAGJMsAAAAwIFkGAACAAckyAAAADEiWAQAA\nYECyDAAAAAOSZQAAABiQLAMAAMCAZBkAAAAGJMsAAAAwsOLJclUdUVXnVtWuqjp+yvj9quq0fvxZ\nVbV1YtwJffm5VXX4RPnJVfWNqvrMoK1bV9U7quoL/f9bLee8AQAAsDGsaLJcVZuSvDTJw5JsS3J0\nVW0bVHtCkktbawcneWGSk/r3bktyVJJ7JDkiycv69pLk1X3Z0PFJ3tVaOyTJu/rXAAAAMK+VvrJ8\naJJdrbXzWmtXJDk1yZGDOkcmOaUffkOSw6qq+vJTW2uXt9bOT7Krby+ttfcl+daU6U22dUqSRy7l\nzAAAALAxrXSyfECSL0+8vrAvm1qntXZlku8k2X/ke4du21q7qB/+WpLbTqtUVcdW1c6q2nnxxReP\nmQ8AAAA2sL2mg6/WWkvSZox7eWtte2tt+5YtW1Y4MgAAANaalU6Wv5LkDhOvD+zLptapqs1JbpHk\nmyPfO/T1qrpd39btknxjjyMHAABgr7HSyfJHkxxSVQdV1b7pOuzaMaizI8kx/fCjkpzZXxXekeSo\nvrfsg5IckuQjC0xvsq1jkrxlCeaBtahqbfwBAAAbwoomy/0zyE9OckaSc5Kc3lo7u6pOrKpH9NVe\nmWT/qtqV5Onpe7BurZ2d5PQkn03ytiTHtdauSpKq+vskH0pyt6q6sKqe0Lf1vCQ/U1VfSPLT/WsA\nAACYV3UXbZmzffv2tnPnzuWdyFq5Ajlm3a+XWNdLnAAAwKqqqo+11rYvVG+v6eALAAAAxpIsAwAA\nwIBkGQAAAAYkywAAADAgWQYAAIAByTIAAAAMSJYBAABgQLIMAAAAA5JlAAAAGJAsAwAAwIBkGQAA\nAAYkywAAADAgWQYAAIAByTIAAAAMSJYBAABgQLIMAAAAA5JlAAAAGJAsAwAAwIBkGQAAAAYkywAA\nADAgWQYAAIAByTIAAAAMSJYBAABgQLIMAAAAA5JlAAAAGJAsAwAAwIBkGQAAAAYkywAAADAgWQYA\nAICBzYupXFU/muRBSfZP8retta9V1cFJvt5a++5yBAgAAAArbVSyXFX7Jfm7JL+YpJK0JP+U5GtJ\nnp/k80mOX6YYAQAAYEWNvQ37uUl+OsmvJbltuoR5zr8mOXyJ4wIAAIBVM/Y27KOTPLO19vqq2jQY\nd36SrUsaFWxkVQvXWQmtrXYEAACwZo29srx/knPmaWO/pQkHAAAAVt/YZPn8JPefMe7QJOcuTTgA\nAACw+sYmy69JcnxVPTbJDfqyVlU/leRpSU5ejuAAAABgNYxNlp+f5F+SvDbJpX3ZB5K8M8nbWmsv\nXobYAAAAYFWM6uCrtXZVkqOq6qXper7+oSTfTJcov3cZ4wMAAIAVN7Y37CRJa+39Sd6/TLEAAADA\nmjDqNuyq+rmqevKMccdV1cOXNiwAAABYPWOfWf7DJDeZMe5G/XgAAADYEMYmy3dP8vEZ4z6Z5EeW\nJhwAAABYfWOT5X2S3HTGuJvl2p+TAgAAgHVvbLL8qSSPnTHusUk+vTThAAAAwOob2xv2nyd5Y1X9\nQ5L/m+TCJAckOTbJLyR59PKEB6yqqtWOoNPaakcAAMBeZuzvLL+pqp6S5LlJfrEvriSXJfmd1to/\nLlN8AAAAsOJG/85ya+3FVfXqJD+ZZP8klyT5YGvtsmWKDWAcV8ABAFhio5PlJGmtfTfJGcsUC8DG\nJ7EHAFgXRifLVbVPkkOT3DHJDYfjW2uvWcK4AAAAYNWMSparaluSNye5S7pnlYdaEskywEbhCjgA\nsJcbe2X5ZX3dX07y70kuX7aIAAAAYJWNTZbvm+Rxer0GAABgb7DPyHqXJLliOQMBAACAtWJssvzC\nJMdV1ablDAYAAADWgrG3YW9Jcrckn62qdyT51mB8a6390ZJGBgAAAKtkbLL8zInhQ6aMb0kkywAA\nAGwIo5Ll1trY27UBAABg3VvxJLiqjqiqc6tqV1UdP2X8flV1Wj/+rKraOjHuhL783Ko6fKE2q+qw\nqvp4VX2yqj5QVQcv9/wBAACw/q1ostx3EPbSJA9Lsi3J0VW1bVDtCUkuba0dnK5jsZP6925LclSS\neyQ5IsnLqmrTAm3+dZLHttbuneT1ue7t5AAAADDV6GS5qo6tqk9U1fer6qrh38hmDk2yq7V2Xmvt\niiSnJjlyUOfIJKf0w29IclhVVV9+amvt8tba+Ul29e3N12ZLcvN++BZJvjp2fgEAANh7jXpmuap+\nPcmL0yWx90pycpIbJHlEkouTvG7k9A5I8uWJ1xcmud+sOq21K6vqO0n278s/PHjvAf3wrDafmOSt\nVfWDJP+Z5CdmzN+xSY5Nkjve8Y4jZwUAAICNauyV5acm+dMkT+pfv6y1dkySOyf5QZJvLkNsS+Fp\nSR7eWjswyauS/MW0Sq21l7fWtrfWtm/ZsmVFAwQAAGDtGZssH5LkfUmu7v/2TZLW2qVJnpvkKSPb\n+UqSO0y8PrAvm1qnqjanu336m/O8d2p5VW1Jcq/W2ll9+WlJfnJknAAAAOzFxibLP0iyT2utJfla\nuivKcy5LcvuR7Xw0ySFVdVBV7Zuuw64dgzo7khzTDz8qyZn9dHckOarvLfugdAn8R+Zp89Ikt6iq\nu/Zt/UySc0bGCQAAwF5s1DPLSf49ycFJ3pnk/Un+oKrOT3Jlkmcn+dyYRvpnkJ+c5Iwkm5Kc3Fo7\nu6pOTLKztbYjySuTvLaqdiX5VrrkN32905N8tp/uca21q5JkWpt9+W8meWNVXZ0ueX78yPkFAABg\nL1bdRdsFKlU9JsmdW2t/2v9W8Ttz7a3P303yyNbae5YtyhW0ffv2tnPnzuWdSNXytj/WiHW/bmJd\nL3EmYt0T1v/S20jLFABgEarqY6217QvVG3VlubV22sTwrqq6R5L7J7lxkg+21i7Z40gBAABgjRn1\nzHJVPaiqbjr3urX2vdbaO/vbpn9QVQ9atggBAABghY3t4OvdSbbNGHf3fjwAAABsCGOT5fkeXtsv\nyVVLEAsAAACsCTOfWa6qrbnuT0Rtn7wVu3ejdD1M/8eSRwYAAACrZL4Ovo5J8kdJWv/34lz3CnPr\nX1+Z5LjlChAAAABW2nzJ8quTvCddQnxmuoT4s4M6lyf5fGvtW8sRHAAAAKyGmclya+1LSb5UVTdI\n8otJvtha+/cViwwAAABWyYIdfLXW/jvJaUlus/zhAAAAwOob2xv2eUl+aDkDAQAAgLVibLL8/CT/\nu6q2LGcwALBoVWvjDwDYUObr4GvSQ5PcOsn5VfXhJBel6w17TmutHbPUwQEAAMBqGJssPyDJfye5\nOMld+r9Jbbd3AAAAwDo1KllurR203IEAAADAWjH2mWUAAADYa4y9DTtVdeMkj0/y4HTPL38rybuT\nvKq19oPlCQ8AAABW3qgry1X1w0k+nuRFSbYnuXH//yVJPl5Vt122CAEAAGCFLeano26V5IGttYNa\na/fvn2N+QJJbJjlpuQIEAACAlTb2NuyHJXlGa+3fJgtbax+sqmcmed6SRwYAG8la+S3m5gcsAGCM\nscnyTZN8dca4C/vxAMBGILEHgNG3YZ+b5NdmjPvVJJ9bmnAAAABg9Y29svxnSV7Td+T1+iQXJfnh\nJEcl+enMTqQBAABg3RmVLLfW/q7/6agTk7xiYtTXk/xWa+31yxEcAAAArIbRv7PcWnt5Vb0iyd1y\n7e8sn9tau3q5ggMAAIDVMDpZTpI+MT5nmWIBAACANWFsB1+pqkOq6pSq+nxVfa///+qqOng5AwQA\nAICVNurKclU9JMlbk/wgyb+ke1b5tkl+PsljquqI1tp7lytIAAAAWEljb8P+8ySfSHJ4a+2yucKq\nulmSt/fjty99eAAAALDyxt6GvS3JSZOJcpK01r6b5KQk91jqwAAAAGC1jE2WL0yy74xx+yb5ytKE\nAwAAAKtv7G3YJyX546r6YGvtq3OFVXVAkj9K8ifLERwAwExVqx1Bp7XVjgCAZTA2WX5wkpsnOa+q\nPpxrO/j6iX74IX0nYEnSWmvHLHWgAAAAsFLGJssPSHJlkouS3Kn/S/86SR44UdfXqwAAAKxro5Ll\n1tpByx0IAMCGtV5uGV8vcQKsgLFXlgEAYO2Q2APLbFHJclXdIckdktxwOK61duZSBQUAAACraVSy\nXFV3TvK6JIfOFfX/Wz/ckmxa8ugAAABgFYy9svyKJHdM8tQkn0tyxbJFBAAAAKtsbLL840ke11p7\n43IGAwAAAGvBPiPrXRhXkwEAANhLjE2W/yTJM6rqJssZDAAAAKwFY39n+bVVdfckF1TVh5NcunuV\ndsySRwcAAACrYGxv2I9LckKSq5LcN7vfku0H5gAAANgwxnbw9cdJ3pTkCa21by9jPAAAALDqxibL\n+yd5mUQZAAAWoWq1I+g0N4LCYo3t4OsDSX5kOQMBAACAtWLsleWnJDm9qi5N8rbs3sFXWmtXL2Vg\nAAAAsFrGJsvn9P9fM2N8W0RbAAAAsKaNTXBPjB6vAQBg4/J8NVzH2N9ZfvYyxwEAAABrxtgOvgAA\nAGCvMfPKclU9fjENtdZOvv7hAAAAwOqb7zbsVyyinZZEsgwAACwvz1azQuZLlg9asSgAAABgDZmZ\nLLfWvrSSgQAAAMBaoYMvAAAAGJAsAwAAwMCKJ8tVdURVnVtVu6rq+Cnj96uq0/rxZ1XV1olxJ/Tl\n51bV4Qu1WZ3nVtXnq+qcqvqd5Z4/AAAA1r/5OvhaclW1KclLk/xMkguTfLSqdrTWPjtR7QlJLm2t\nHVxVRyU5KcljqmpbkqOS3CPJ7ZO8s6ru2r9nVpuPS3KHJHdvrV1dVT+0/HMJAADAerfSV5YPTbKr\ntXZea+2KJKcmOXJQ58gkp/TDb0hyWFVVX35qa+3y1tr5SXb17c3X5pOSnNhauzpJWmvfWMZ5AwAA\nYINYVLJcVftU1T2r6sFVdZM9mN4BSb488frCvmxqndbalUm+k2T/ed47X5t3SXdVemdV/WtVHTJj\nvo7t6+y8+OKL92C2AAAA2EhGJ8tVdVySryX5VJIzk9ytL3/zGn4WeL8k/9Va257k/yY5eVql1trL\nW2vbW2vbt2zZsqIBAgAAG1TV2vhjj4xKlqvqN5P8VZI3J3lMkskl/v4kvzRyel9J9wzxnAP7sql1\nqmpzklsk+eY8752vzQuT/GM//KYkPzoyTgAAAPZiY68sPz3Jn7fWjk2XdE76XPqrzCN8NMkhVXVQ\nVe2brsOuHYM6O5Ic0w8/KsmZrbXWlx/V95Z9UJJDknxkgTbfnOSn+uEHJ/n8yDgBAAD2Dqt95XuN\nXgEf2xv2QUnOmDHue0luOaaR1tqVVfXkvq1NSU5urZ1dVScm2dla25HklUleW1W7knwrXfKbvt7p\nST6b5Mokx7XWrkqSaW32k3xektdV1dOSXJbkiSPnFwAAgL3Y2GT5kiRbZ4y7W3a/lXqm1tpbk7x1\nUPasieH/SvLoGe99bpLnjmmzL/92kv85NjYAAABIxt+G/c9JnlVVd54oa1V1myRPS3e7MwAAAGwI\nY5PlZya5PMlnkrwzSUvyoiTnJLkqyYnLEh0AAACsglHJcmvtkiTbk/xpkhsk+WK6W7hfkuT+rbXv\nLFuEAAAAsMIWfGa5qjYluWeSr7bWnpPkOcseFQAAAKyiMVeWW5KdSe6zzLEAAADAmrBgstxauzrJ\nl5PcZPnDAQAAgNU3toOvv03y1KradzmDAQAAgLVg7O8s3yzJXZKcV1VvS3JRutuz57TW2h8tdXAA\nAACwGsYmy38wMfz4KeNbEskyAAAAG8KoZLm1NvZ2bQAAAFj3JMEAAAAwIFkGAACAgVG3YVfV1blu\nh167aa1tWpKIAAAAYJWN7eDrxOyeLO+f5GeT7Jfk1UsYEwAAAKyqsR18PXtaeVVtSvJPSb6zhDEB\nAADAqrpezyy31q5K8rIkT12acAAAAGD1LUUHX/slufUStAMAAABrwtgOvu44pXjfJPdM8rwkO5cy\nKAAAAFhNYzv4uiDTe8OuJF9MctxSBQQAAACrbWyy/Pjsniz/V5IvJflo/+wyAAAAbAhje8N+9TLH\nAQAAAGvGqA6+quq8qrrXjHH3rKrzljYsAAAAWD1je8Pemq7X62lumOROSxINAAAArAGL+emoaR18\nJcn2JN9eglgAAABgTZj5zHJVPS3J0/qXLck/VdUVg2o3Svcby6cuT3gAAACw8ubr4Ou8JO/qh49J\n91vKFw/qXJ7ks0lesfShAQAAwOqYmSy31t6S5C1JUlVJcmJr7fwVigsAAABWzdifjvqN5Q4EAAAA\n1opRyXKSVNW+SR6W5G7pesCe1Fprz1nKwAAAAGC1jEqWq+r2ST6Q7iekWpLqR032kC1ZBgAAYEMY\n+9NRL0jXudcd0yXK90ty5yTPTbKrHwYAAIANYext2A9M8rtJvtq/vrq1dkGSZ1XVpiQvSnLk0ocH\nAAAAK2/sleX9k3y1tXZ1ku8ludXEuDOTPGSJ4wIAAIBVMzZZvjDJbfrhLyb52Ylxhyb5r6UMCgAA\nAFbT2Nuw353kwUnenORvk7y0qu6d5L+THN6XAQAAwIYwNll+ZpJbJ0lr7a+ranOSxyS5cZLnJzlx\necIDAACAlTcqWW6tXZLkkonXL07y4uUKCgAAAFbT2GeWkyRVtU9V3bOqHlxVN1muoAAAAGA1jU6W\nq+q4JF9L8ql0PWDfrS9/c1X9zvKEBwAAACtvVLJcVb+Z5K/SdfD1mCQ1Mfr9SX5p6UMDAACA1TH2\nyvLTk/x5a+3YJG8ajPtc+qvMAAAAsBGMTZYPSnLGjHHfS3LLpQkHAAAAVt/YZPmSJFtnjLtbkq8s\nSTQAAACwBoxNlv85ybOq6s4TZa2qbpPkaemeZQYAAIANYWyy/Mwklyf5TJJ3JmlJXpTknCRXJTlx\nWaIDAACAVTAqWW6tXZJke5I/TXKDJF9MsjnJS5Lcv7X2nWWLEAAAAFbY5rEVW2vfTfKc/g8AAAA2\nrJlXlqvqoVV105UMBgAAANaC+W7DfkeSbXMvqmqfqnpfVR2y/GEBAADA6pkvWa4prx+Q5GbLFw4A\nAACsvrG9YQMAAMBeQ7IMAAAAAwv1hn1AVd25H940UfbtYcXW2nlLGhkAAACskoWS5TdMKXvzjLqb\nZpQDAADAujJfsvwbKxYFAAAArCEzk+XW2ikrGQgAAACsFTr4AgAAgIEVT5ar6oiqOreqdlXV8VPG\n71dVp/Xjz6qqrRPjTujLz62qwxfR5ouq6rLlmicAAAA2lhVNlqtqU5KXJnlYkm1Jjq6qbYNqT0hy\naWvt4CQvTHJS/95tSY5Kco8kRyR5WVVtWqjNqtqe5FbLOmMAAABsKCt9ZfnQJLtaa+e11q5IcmqS\nIwd1jkwy97z0G5IcVlXVl5/aWru8tXZ+kl19ezPb7BPpFyT5/WWeLwAAADaQlU6WD0jy5YnXF/Zl\nU+u01q5M8p0k+8/z3vnafHKSHa21i+YLqqqOraqdVbXz4osvXtQMAQAAsPFs2A6+qur2SR6d5MUL\n1W2tvby1tr21tn3Lli3LHxwAAABr2kony19JcoeJ1wf2ZVPrVNXmJLdI8s153jur/D5JDk6yq6ou\nSHLjqtq1VDMCAADAxrXSyfJHkxxSVQdV1b7pOuzaMaizI8kx/fCjkpzZWmt9+VF9b9kHJTkkyUdm\ntdla+5fW2g+31ra21rYm+X7faRgAAADMa/NKTqy1dmVVPTnJGUk2JTm5tXZ2VZ2YZGdrbUeSVyZ5\nbX8V+Fvpkt/09U5P8tkkVyY5rrV2VZJMa3Ml5wsAAICNpbqLtszZvn1727lz5/JOpGp52x9rzLpf\nL7GulzgTse4J63/pWaZLzzJdepbp0rNMl55luvQs06W3kZbpEqiqj7XWti9Ub8N28AUAAAB7SrIM\nAAAAA5JlAAAAGJAsAwAAwIBkGQAAAAYkywAAADAgWQYAAIAByTIAAAAMSJYBAABgQLIMAAAAA5Jl\nAAAAGJAsAwAAwIBkGQAAAAYkywAAADAgWQYAAIAByTIAAAAMSJYBAABgQLIMAAAAA5JlAAAAGJAs\nAwAAwIBkGQAAAAYkywAAADAgWQYAAIAByTIAAAAMSJYBAABgQLIMAAAAA5JlAAAAGJAsAwAAwIBk\nGQAAAAYkywAAADAgWQYAAIAByTIAAAAMSJYBAABgQLIMAAAAA5JlAAAAGJAsAwAAwIBkGQAAAAYk\nywAAADAgWQYAAIAByTIAAAAMSJYBAABgQLIMAAAAA5JlAAAAGJAsAwAAwIBkGQAAAAYkywAAADAg\nWQYAAIAByTIAAAAMSJYBAABgQLIMAAAAA5JlAAAAGJAsAwAAwIBkGQAAAAYkywAAADAgWQYAAIAB\nyTIAAAAMSJYBAABgYMWT5ao6oqrOrapdVXX8lPH7VdVp/fizqmrrxLgT+vJzq+rwhdqsqtf15Z+p\nqpOr6gbLPX8AAACsfyuaLFfVpiQvTfKwJNuSHF1V2wbVnpDk0tbawUlemOSk/r3bkhyV5B5Jjkjy\nsqratECbr0ty9yT/I8mNkjxxGWcPAACADWKlrywfmmRXa+281toVSU5NcuSgzpFJTumH35DksKqq\nvvzU1trlrbXzk+zq25vZZmvtra2X5CNJDlzm+QMAAGADWOlk+YAkX554fWFfNrVOa+3KJN9Jsv88\n712wzf72619L8rZpQVXVsVW1s6p2XnzxxYucJQAAADaavaWDr5cleV9r7f3TRrbWXt5a295a275l\ny5YVDg0AAIC1ZvMKT+8rSe4w8frAvmxanQuranOSWyT55gLvndlmVf1Rki1J/r8liB8AAIC9wEpf\nWf5okkOq6qCq2jddh107BnV2JDmmH35UkjP7Z453JDmq7y37oCSHpHsOeWabVfXEJIcnObq1dvUy\nzxsAAAAbxIpeWW6tXVlVT05yRpJNSU5urZ1dVScm2dla25HklUleW1W7knwrXfKbvt7pST6b5Mok\nx7XWrkqSaW32k/ybJF9K8qGuj7D8Y2vtxBWaXQAAANap6i7aMmf79u1t586dyzuRLnFffWPW/XqJ\ndb3EmYh1T1j/S88yXXqW6dKzTJeeZbr0LNOlZ5kuvY20TJdAVX2stbZ9oXp7SwdfAAAAMJpkGQAA\nAAYkywAAADAgWQYAAIAByTIAAAAMSJYBAABgQLIMAAAAA5JlAAAAGJAsAwAAwIBkGQAAAAYkywAA\nADAgWQY7ZLUNAAAgAElEQVQAAIAByTIAAAAMSJYBAABgQLIMAAAAA5JlAAAAGJAsAwAAwIBkGQAA\nAAYkywAAADAgWQYAAIAByTIAAAAMSJYBAABgQLIMAAAAA5JlAAAAGJAsAwAAwIBkGQAAAAYkywAA\nADAgWQYAAIAByTIAAAAMSJYBAABgQLIMAAAAA5JlAAAAGJAsAwAAwIBkGQAAAAYkywAAADAgWQYA\nAIAByTIAAAAMSJYBAABgQLIMAAAAA5JlAAAAGJAsAwAAwIBkGQAAAAYkywAAADAgWQYAAIAByTIA\nAAAMSJYBAABgQLIMAAAAA5JlAAAAGJAsAwAAwIBkGQAAAAYkywAAADAgWQYAAIAByTIAAAAMSJYB\nAABgQLIMAAAAA5JlAAAAGJAsAwAAwMCKJ8tVdURVnVtVu6rq+Cnj96uq0/rxZ1XV1olxJ/Tl51bV\n4Qu1WVUH9W3s6tvcd7nnDwAAgPVvRZPlqtqU5KVJHpZkW5Kjq2rboNoTklzaWjs4yQuTnNS/d1uS\no5LcI8kRSV5WVZsWaPOkJC/s27q0bxsAAADmtdJXlg9Nsqu1dl5r7YokpyY5clDnyCSn9MNvSHJY\nVVVffmpr7fLW2vlJdvXtTW2zf89D+zbSt/nIZZw3AAAANojNKzy9A5J8eeL1hUnuN6tOa+3KqvpO\nkv378g8P3ntAPzytzf2TfLu1duWU+tdRVccmObZ/eVlVnbuIeVott0lyyfVqoWppIlnYeol1vcSZ\niHU5rJc4k/UT63qJM1k/sa6XOJP1E+t6iTNZP7GulziT9RPreokzWT+xrpc4k/UT63qJM0nuNKbS\nSifLa1Jr7eVJXr7acSxGVe1srW1f7TjGWC+xrpc4E7Euh/USZ7J+Yl0vcSbrJ9b1EmeyfmJdL3Em\n6yfW9RJnsn5iXS9xJusn1vUSZ7J+Yl0vcS7GSt+G/ZUkd5h4fWBfNrVOVW1Ocosk35znvbPKv5nk\nln0bs6YFAAAAu1npZPmjSQ7pe6neN12HXTsGdXYkOaYfflSSM1trrS8/qu8t+6AkhyT5yKw2+/e8\nu28jfZtvWcZ5AwAAYINY0duw+2eQn5zkjCSbkpzcWju7qk5MsrO1tiPJK5O8tqp2JflWuuQ3fb3T\nk3w2yZVJjmutXZUk09rsJ/mMJKdW1f9J8om+7Y1iPd02vl5iXS9xJmJdDuslzmT9xLpe4kzWT6zr\nJc5k/cS6XuJM1k+s6yXOZP3Eul7iTNZPrOslzmT9xLpe4hytuguwAAAAwJyVvg0bAAAA1jzJMgAA\nAAy11vyt8F+Sk5N8I8lnJsrune53pD+ZZGeSQ/vy3+vLPpnkM0muSnLrJDdM18HZp5KcneSPJ9p6\n/8R7vprkzRPjHtKXn53kvYuI+W4TbX4yyX8meWqSFyT5XJJPJ3lTklv29R87qH91knv34x7T1z87\nyUkT03hQko+neyb9UUuwTO+V5ENJ/j3JPyW5eV9+gySn9OXnJDlh4j1HJDk3ya4kx0+UH9bH9skk\nH0hycF/+W307c+XbFhHz1HWY5KAkZ/UxnJZk3zHTSnLHJJcl+d1B+aZ0z+z/8/X4zM5a/89O18v8\nXPnDJ95zQj8P5yY5fKGYZi3jPVn3ffn/6j+bZyd5/ojP5dH98v10krcluU1fftpE/QuSfHLMct/D\ndT912+3j/nQf3weT3GuirVsmeUM/r+ckuX9fPnPdLHLdz4r1of36+ky67Wnz4H0/nsG2nOSkvv5n\nkjzm+q77Pdj2tyb5wcQy+Zsp7e0YtDV1OY5pa4G4L8i12/POvmzW/nTmtJI8N8mXk1w2aH+//rO7\nK93+ZOv12P6nxTrrmHWLfpnPfV5+Y6Kd5/dl5yR5Ua59FOzH+vZ3TZbv4bqfFdet+mX66XSf53uO\n2IZuneQdSb7Q/7/VQm0tYpk+rV8Wn0ny9+m2s1f2y+3TfTw3nW9dJtk/XUemlyV5yUTbN8t193OX\nJPnL67FMp34uJ8bvtg/M7GPpq5OcPxHbvRfabyzn+k/3ayrvTtcfztlJnrLQfqQf96P9uLP78Tcc\nuXwXe9y/U5J39XG/J8mBE21dNbEcd0yUz7tv3sN9wNRzgH7ctGPtoRN1P5XkFxba3q5HbLOW6azt\n6YUTsX0+ybcH7d08yYW57ja1R/uoRcT65L7tlv7coy+vfnq7+vm478S4tyX5dgbndrPmew9ifUr/\nGTp7Yl3POrbum+RVffmnkjykL5+5L0q333h3unPBT2cPz1FW4m/VA9gb/9IlhffNdXfwb0/ysH74\n4UneM+V9P5+ud/C5DWhuw79Bup3sT0x5zxuT/Ho/fMt0B4Q79q9/aA/j35Tka+l24j+bfkec7kT4\npCn1/0eSL/bD+yf5jyRb+tenJDmsH96a7gD0miw+WZ62TD+a5MH98OOTPKcf/pUkp/bDN053Iri1\nn68vJrlzv+F/Kn1Cmm6H+iP98G8neXU/PHnwfESSty0i5qnrMMnpSY7qy/8myZPGTCvdTvEfsnuy\n/PQkr8/1SJbnWf/PHk6vr7OtX377pTsJ+GKSTfPFNGsZ7+G6/6kk70yy36zP+uBzuTndSddcgvz8\nJM+e8p4/T/KsMct9T9b9oM7ktvuTufZE/WFJzpqod0qSJ/bD++baBGvqutmD9T0t1p9Ml6DdtS8/\nMckTBp+RM5O8Nf22nOR/pks4Nie5Sbrtc+5Au0frfp71P2vb35rBlyqDtn6x/1wOk+Vpn/F52xoR\n9wWZOCnqy6buT+ebVrp9xu2ye7L82+mT6nQdZZ62xLFOPWYl+YOJuLek66hz3/4z82/9Z2NTuhOu\nh/T1PtLPRyX517l293Ddz4rrBUn+qB++e5J3jdiGnp8+0Uty/MR8zWxrZNwHpEsYb9S/Pj3J43Ld\nffxfTEx76rpMtx09IN0XqS+ZZ3ofS/Kg67FM5z3OZ7APzPzH0ldnxvE9U/Yby73+02079+2Hb5Zu\nXzQX66z9yOZ0J/f36l/vn4nj2wIxL/a4/w9JjumHH5rktRNtXTal/X0yz755Kf5y3XOAqcfadOdW\nc5+Z26U7vs69nrq9XY94Zi3TqdvT4L3/K13HwJNlf5XuODCZLO/RPmoRsd4n3X7+glw3WX54P73q\n600e+w9LlxcMk+UF53tEnPdMlyjfuP+8vzPJwfNsE8cledXcZyDdPmefKe1esy9K1xHY3Od8W5IL\nlvJzupR/bsNeBa2196U7gbhOcbpvs5Lum/mvTnnr0em+gU7rXNaX36D/a5OVq+rm6Xaub+6LfiXJ\nP7bW/qNv4xt7OAuHpUsyvtRae3tr7cq+/MPpfs96Wtyn9sN3TvKF1trF/et3JvmlPp4LWmufTne1\nb1FmLNO7JnlfP/yOuemkW0436X+D+0ZJrkj3LemhSXa11s5rrV3Rx3zkxHt2Wz+ttf+cmN5NMlgH\nC8Q8ax0+NN3JR9IdVB650LSq6pHpTr7OnqiTqjowXZLyirFxjXDN+p+nzpHpvpC4vLV2frpvRQ9d\nIKYx28BuZqz7JyV5Xmvt8r7OtM/65Oey+r+bVFX1cVxn+n35L6ffBvuyqct9RMzzbr/Dbbe19sHW\n2qX96Gu2s6q6RboTxlf29a5orX17MbHsYaxXJbmitfb5vnxy+0q6E5A3pjtBmrMtyftaa1e21r6X\n7mTziLnJZA/WfR/fYrb9marqpum+xPk/Y6e91EbuT4fv+XBr7aIpo45Mt/9Iuv3JYf1neKnMWmct\nyc36ad003bq5si+/YbqT4/3SfY6+XlW3S3dy9+HWnTW9Jv0+b8EAFncs3ZYuEUtr7XNJtlbVbRfY\nhiaX4TX74lltjYl5wuYkN+qPQzdO8tW5fXy/7G6Ua/cJU9dla+17rbUPJPmvWROpqrumO3l9/5ig\npi3T+T6XM/aB8x1L5zNtv7GoWLPI9d9au6i19vG+/LvprnQe0L9n1n7kZ5N8urX2qf5932z9r7OM\niHlRx/3JuNNdhVtoOe6f+ffNS2HyHGDqsba19v2Jz8wN03+Wl+OYNWuZzrM9TbrmvLqv+2NJbpvu\nS5e5sj3eRy0i1k+01i6Y8pYjk7ymf9+Hk9yyjyettXcl+e6UaYyZ74X8SLrEfG49vjfdl8mztonJ\n7esb6a54b59scMq+aI+P+ytNsrx2PDXJC6rqy0n+LN0trNeoqhunO7F840TZpqr6ZLoDyztaa2cN\n2nxkum9P55Ksuya5VVW9p6o+VlW/voexHpWJncuEx6f7BmzoMRP1dyW5W1Vt7U8SHpnuNqjlcHau\nPbA8emI6b0jyvSQXpbvK/WettW+lO0B+eeL9F+bag+YTk7y1qi5M8mtJnjdXqaqOq6ovprsK8TuL\nCXC4DtN9G//tiYPMZAxTp9Wf5D8jyR9PmcRfJvn97MEXEPMYrv8nV9Wnq+rkqrpVXzbfspwV08xl\nvAfumuSBVXVWVb23qn58Sp1rPpettf9Od9D/93Q77G3Z/afmHpjk6621LyQLLvcFLbD9DrfdSU/I\ntdvZQUkuTvKqqvpEVb2iqm4yUXfaurnesab7ln1zVc0dDB+VfvuqqgOS/EKSvx4086kkR1TVjavq\nNumuSMxtk0u57pPZ236SHNQvq/dW1QMnyp+T7s6B709pb9ZynNXWGC3J2/t98bFTxg/3p4ud1jXb\nYL8/+U66E+k9MS3WWcesl6Q70fpquu3pKa21q1trH0p3sn9R/3dGa20uMblwYlrX2eftgVlxfSrd\nyV6q6tB0V8UOzPzb0G0nvoj4WrqT6PnaGqW19pU+tv9Ityy+01p7e9/eq/pp3T3Ji/u3XJ91OXcl\nek9OmKe55nM5zz5wvv1/kjy3355eWFX79W3N2m8s1mLX/zWqamu6K3xz++JZ+5G7JmlVdUZVfbyq\nfn8xAS7yuH9N3OmWz82qam7d37CqdlbVh/svLZLuNtep++YlNHkOMPNYW1X3q6q529R/q5+/hY5Z\ne2TW8XTG9jT3njv18ZzZv94n3THgdwfNL+k+asS5+3Da821Ls6Yxc75H+ky69bp/n388PN3naNY2\n8akkj6iqzVV1ULrb1oefu+G+6NlJfrU/7r813Zdla5Jkee14UpKntdbukO5ZpuGJ+s8n+bc+qUuS\ntNauaq3dO90O/9CquufgPdf5xizdN9k/lu6q3uFJ/rD/pme0qto33S3A/zAo/9/prh68blB+vyTf\nb619po/50n5eT0v37dIF6a5SLYfHJ/ntqvpYuturrujLD+2neft0O8r/v6ruvEBbT0v3PMWB6Z7L\n+Iu5Ea21l7bW7pLupOGZiwlwuA7T7djmqz9tWs9O8sKJbyuTJFX1c0m+0Vr72GJims+U9f/XSe6S\n7jmxi9IdaOZ7/3wxzVzGe2BzuucNfyLdc/+n99+yzsVxnc9lVd0g3efyPuk+F5/O4Aur7L49PTtT\nlvtYC2y/w2nNxf1T6ZLlZ0zM532T/HVr7T7pvgQ6vh+3qHWzmFiT3CPdge+FVfWRdN9uz23Hf5nk\nGa21qwdtvD3dAfGD/bx9aOI9S7nuk9nb/kXpHkO5T/pHAarq5lV17yR3aa29aUpbs5bj1LYWEeMD\nWmv3TXdb/XFV9aC5EVP2p9d3WtfXtFhnHbMOT/ds2u3TLbOX9Mv44HRJ9IHpTvYeugdfMIwxK67n\npbsq88l0J2WfSPf5m28bukZ/gtcWaGuU/guXI9Mdf26f7o6WX+2n8xt92TnpvtC7vmZ9ub1oUz6X\nz87i94EnpDvO/Xi6ffTcvmzqfmMPLHb9J7km8X9jumcz576knLUf2Zzu9vfH9v9/oaoOGxvgIo/7\nv5vkwVX1iSQPTtd/wlzcd2qtbU931+BfVtVd+s/prH3z9TblHGDmsba1dlZr7R7p1vUJVXXDjNze\nFmvW8XSB7emoJG+YuCvgt5O8tbV2YZbRiHP3pZjG9dqP9F9knpTuCvvb0u3Tr8rsbeLkdIn8znTb\n8gez++duuC86Ot0jVwemS8Zf239hsfa0NXAv+N74l8EzaOm+KZ7r7KSS/Oeg/puS/Mo87T0r1+1c\n4zZJvpmJTifS7ZAmOwJ7ZZJHLzLuI5O8fVD2uHQnvjeeUv+FSf5gnvaOTd8hxETZq7PIZ5anLdPB\nuLsm+Ug//NIkvzYx7uR0t9feP93VjrnyE/q/Lemfbe3L75jks1OmsU+6KwR7+pl4VrqDzSW59tme\n68Q0bVq59kuHC9Ld+vKtdJ1F/Gm6ndcF6b5h/H6Sv7uen9vd1v+05T+37CbGndHPy9SYxi7jRWxP\nb0vyUxOvv5j+Oflpn8t0B/PJZxgflO6gOfd6c5Kv57qdq0xd7tdj3c8977fbttuX/2g/H3edKPvh\nTDznk+7q978sZtu4PrFOlP1sktP74fMnlstl6b49f+SUdl6f7gB5vdb9QvOXiW1/yrj3pLtV7Enp\nroRe0H8+r8j0fiPmm857kmzfw2X67In1/7jM2J/ON63s/szyGbm2o6rN6fYre9QpzbRYM+OYleRf\nkjxwov6Z6RKC30vyh4PP0e+ne57xcxPlRyf52z1d97PiGryn+nV98/m2oXQdVN2uH75dknPna2sR\nMT86ySsnXv96kpcN6jwo/bOIC63L/jOz2zPL6Trj+fwerOPdPufTPpeZfeyZeiydMp2HTMzjqP3G\nUq///vUN+mX89HmmM3kOcVSSUybG/WGS39vD7Wkxx/2bJrlwRjuvzpTzpkzsm5fiL4NzgCxwrJ0o\nPzPdvnbUMet6xjjtGHXN9jRR9okkPznx+nXp7va4oF8f/5nuS5brtY9aTKzZ/Znlv01y9MTra/ZJ\n/etrtqEZ7e8233sY558k+e1B2XzH1g9mohPaTNkXpbtKfYeJ1+dlD/tSWu6/tZnB752+mu5bw6R7\nduULcyOqe8bjwUneMlG2papu2Q/fKMnPpOtZcM6j0m0gk88yvSXJA/rbJG6c5H7pvnVajOHzHUek\nO+F5RGvtOrcv9t8Q/fL/a+/OY+0oyziOf39QKeLCVlAUyxIJRZYYxaQKKAqKCiKbWrEp4BIxQRQB\npeKCexUVUSNoNCKbBBAQo5FakSWNFdmE0msRUCuryBIEsWnh8Y/nnZ6505l7zzn3KtL+PsnJvTNn\n5p1n3tnOO+8779B7LrQav3n5uzF5J28yn6dtW846ZC3s6eWrZWQeU5r/zCTz7vfAdpK2KXdPZ5E9\n4z4EbFirhX89Jd8kbVdb5L7Utlsf8bVtwxGyqeIhZbLDKNu9a1kRsUdEbB0RW5N39L4YEd+OiLkR\nsWUZP4vsHG52v/F1aG7/LWrfHUg23YHMt1mSppYmOduRJ9WumDrzeEiXkM18q+dk1iMvfl375V3A\nSyRt1rH8vcmL5ao7zl353k9w4xy/qx27kqYDF5E3eapn0YiIe4G/Sdq+jNqL7MRvrG0zkK5Ya8fX\nVLJ26PQS0za1fLmQvMBeUpqebVrm2YUs/M9n8rd957Ff1mXd8v+25H55R0ScFhEvKDHvTl7U9yzT\nteZjV1p9xvcsSc+p/id/0C7uOp8OuaxLyfMH5D51eZRfJIPoipXua9Yycj9E+Rzv9iXWZWQN2ZTS\nkuM1wEhkM+dHJM0sNVJzqF3rhtAal6SNynkdstn/VRHxyFjHEKPzsH4ubk1rgBiXATOVjySoLHOk\n1L5XzxruT++cMOy2bG2hMqiu/XKMc2DXtXTV8VTW8QDK8dR13hgi3IG2f4njB+S+OKpFyxi/IS4D\ndi7bb0pZ3hL6MMR1f1qttm0ueXMfSRur14R9GrAbvXN/67l5kjT3qdZrbdn2U8r4rcja87+Mc7wN\npSNPl45xPCFpBtlD+m+rcRHxroiYXvbB48hnhU+YzHNUH7/dmy4F5ijNJCtJ2vqoqNLXWOs9YKzV\nfjSd0vnlGNfWDcr1AUmvB1ZGRH27tp2L6teKHchn2+/n/9FTXVpfGz/kDnMPsIKsxXgP+QPtOrLd\n/++Al9emP5zSe3Nt3C70ultfzOo99F4BvLFl2ceTJ6bFlK7gB4j7WWSN14a1cbeRz1O0vdJkT2BR\nx/ovKZ9ZtfGvKPnxWFnOLRPM0w+RPVveSt4drO42P5tsQnRLieH4WjpvLtPfDpxYG38gvS7xrwC2\nLeNPLencSF7sdhwg5tZtSHaCdk3J2wvo9TI57rLo7rl3TyZ4d7Fj+59F73VLlzL6jueJJR+X0tJz\nZDOmrjwectuvR9ZYLyZfofG6PvbLI8kfLTeRr0TYtPbdGeQzV10xtOb7oNu+69glbyg9RO84u7b2\n3UvJpk83kT9cql6zO7fNgNu9az89ueTXUjrOJdRqO8gLYXXcL6L2yphht/0Qx/7B9I6h64G3tKS3\nNaNrqlrzsZ+0xoh527Ku1etDTizjW8+nYy2L7L/gTrIPgDspvbiX/L6gpHnNIHnaZ6yt1yyy6d/8\nkmeLgdll/LpkLclI2Qe+XlvGrmXa28lnnvt9dVTf11Kytu7Wsr9eRDlOxjmGNiVf2/MnsjPKTcZL\na4B8/Qz5I3Zx2cemkr2FV/l2Dr2az85tSdZEPUjWxt7J6NqcO4AZA8bVlqed1/nafCcxuoas61p6\neW0dz6bltTb02bpsMrZ/mT7Ktm++Hq71PFK+m03v1V9fGS/W2nyDXvcPKfvfreR1oBr/KnrnzJsZ\n/TaCcc/NQ54L2n4DtF5ryb4n6uesA2rztB5vE4hrtTwlW9+1Hk+1/XXeGGkezujesIc6Rw2w/Y8u\n+/BK8obP98t4ka0hby/rsmstravJwuXjZd59xlvvAWO9mjxX/4HeW2u6rq1bl/1thDxXbtVIa7Vz\nEdk3zMKS/o3AGyZrX53sT7WSZmZmZmZmZla4GbaZmZmZmZlZgwvLZmZmZmZmZg0uLJuZmZmZmZk1\nuLBsZmZmZmZm1uDCspmZmZmZmVmDC8tmZrbWkhR9fP7yVMc5mSStX9brhCHm3VXSSZKe2+f0iyQt\nGDzKzvRmlNhnTVaaZmZmXaY81QGYmZk9hV7ZGL6YfO/jSbVxy/9n0fxvLCfXe9kQ8+4KfJp85+sj\nkxmUmZnZ/xsXls3MbK0VEYvqw5KWA/9oju8iaWpEPG0K07V4+1o/MzOztZmbYZuZmfVB0nmSbpP0\n6tK8+HHgs+W7OZKulHS/pH9Kuk7SoY35q+bPn5B0rKS/lml/LWn7xrT7lWU8IulRSSPNZtOSXi7p\nUkkPSnq8THNc7ftFkhZIOkjSH8qNgHe3NcOWNE/SSkk7S7qqpHeXpE9KUpnmSOC0Msvfas3Unz9A\nHlbNqI+Q9CVJ90p6SNIlkrZoTPtsSd8r6/dPSRcBrcuStLekK0pePSrp55J2qH3/MknLJc1rzPe1\nsq479bsOZma29nDNspmZWf+mAWcBXwaWAI+V8dsA5wG3leHXAmdJWi8izmik8V7gFuAoYAPgq8DF\nknaKiCclzQAuAs4lmzyvBLYDXlQlIGl3YAEwAhwN3A1sXz51OwEnk4X6ZcD9Y6ybgJ8C3wU+D+xX\n5lsBzCsxbQN8FNi/ltYDY6TZ5dPAlcDhwAvJPDgD2Kc2zQ+Bt5RpbwDeBJy5WtDSQcAFZBP6Q4F1\ngbnAVZJ2iYh7IuJ6SXOBkyXNj4jLJb0JOAY4KiIWD7EOZma2hnNh2czMrH8bAu+IiMvqIyPiM9X/\nktYBfkMWbj9AFgLrHgP2j4gnyvTPIAvgLwWuJ58LngK8v9bE+9eNNL5OFpBfGRH/LuMub4l3M+C1\nETFSi2/9jnVbB/hmRHyjDM+XtDHwMUnfioi/S/pz+e6GiLizI51+LI2Iw2oxbQF8TtImEfGgpF2A\nQ4BjGvFsRBawq/nWAU4FLouIQ2rjrwTuAD4EVDXopwBvIG9i7ENul59FxHcmsB5mZrYGczNsMzOz\n/v2rWVCGVc2Lz5d0N1kTvAKYzeo1vZAFuydqwzeXv9PL3+uBJ4ELShPqaY1lbQS8AjizVlDusrRe\nUO7D+Y3h84CNgB1app2InzeGm3kwc4x46nYEtgTOljSl+pCdj/0eeHU1YUQEcBhZ83wtuZ3ePZGV\nMDOzNZsLy2ZmZv27tzmiFF4XADOA44HdycLsOUBbLe6DjeGq9nh9gIhYQjY5Xp9sin2fpIWSdivT\nbVr+9lOze08f09Td1zH8wgHTGc+YeQBUzy93xVPZvPw9h7xBUf/sTS+vAIiI+4DLgKnAWRExTBNy\nMzNbS7gZtpmZWf+iZdweZGHygIi4thpZmlcPt5CIXwG/Kk2mdwe+APxC0nR6zwj3U4Bti3cszyOb\nd9eHAe4aMJ2Jqgr5XfFUqrw4FriqJZ1RNe+S9gXmkDXLH5Z0bkTcNPFwzcxsTeSaZTMzs4nZoPxd\nUY2QtDnw5okmHBH/jogFwNeA5wLTI+Jh4BpgjqSpE11Gw9sbw7OAh8mOxKBXA/zMSV5uU/Vqq7Z4\n6m4mC9M7RMS1LZ9VHXeVXrt/CPyEvAExAvxY0n97XczM7GnKNctmZmYTczXZadd3JX2WLNR+imwy\nvOWgiUk6mmzG/UuyqfVmwMfJ3qz/WCb7CNnp10JJp5AFxheThcaPDLkeTwJHS1oPuBHYl3zu+oSI\nqHr9XlL+flDSueRzvzdGxMohl9kqIm6SdCEwr8RzA3nzYa/GdE9IOop8vnsDsiD8APmKqd2AWyPi\n2+X1Vz8ia5rfFxHLJb0TuI7sLO0Dkxm/mZmtGVyzbGZmNgERcTdwMFnb+hPgc8C3gAuHTPIGslOt\nLwPzgW+StaB7RcSKssyFZPPvvwPfITvMOob+nmPuEuQrofYjXyH1NvK1TV9ZNUHE74Avkj1VLyQ7\n0Zq2WkqT4wiyl/C55GurtiKbUI8OOuJi8lVdmwA/IJ9JnlfiuqZMdiz5DPPsiHiozPdHsrfsIyW9\n9b+0DmZm9jSm7BzSzMzM1laS5gHHRYRbnJmZmRWuWTYzMzMzMzNrcGHZzMzMzMzMrMHNsM3MzMzM\nzMwaXLNsZmZmZmZm1uDCspmZmZmZmVmDC8tmZmZmZmZmDS4sm5mZmZmZmTW4sGxmZmZmZmbW8B/2\noTOupqYAAAACSURBVEglD1+s8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb91fe10290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the feature importances of the forest\n",
    "count = 20\n",
    "plt.figure(figsize=(16, 8))\n",
    "# plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "#        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.bar(range(count), importances[indices[:count]],\n",
    "       color=\"r\", align=\"center\")\n",
    "\n",
    "# plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xticks(range(count), indices[:count])\n",
    "plt.xlim([-1, count])\n",
    "plt.xlabel(\"Transcript Index\", fontsize=16)\n",
    "plt.ylabel(\"Feature Importance\", fontsize=16)\n",
    "# plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dumping the variables to pickle\n",
    "To save processing time for future runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f424c87bbcaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'indices' is not defined"
     ]
    }
   ],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"indices.pkl\"):\n",
    "    with open(\"indices.pkl\", 'wb') as out:\n",
    "        pkl.dump(indices, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"X.pkl\"):\n",
    "    with open(\"X.pkl\", 'wb') as out:\n",
    "        pkl.dump(X, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"y.pkl\"):\n",
    "    with open(\"y.pkl\", 'wb') as out:\n",
    "        pkl.dump(y, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.iloc[:, indices[:10000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"X_train_reduced.pkl\"):\n",
    "    with open(\"X_train_reduced.pkl\", 'wb') as out:\n",
    "        pkl.dump(X, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Implementing PCA on the selected important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=512)\n",
    "X_new = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 369)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting observation, after trying PCA we get a worse answer. This is because the fact that we have very less data to train on.<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation on RandomForestClassifier\n",
    "<br>\n",
    "<b>Parameters for the Forest :</b>\n",
    "- Number of trees = 200\n",
    "- Max depth of a tree - 60\n",
    "\n",
    "<b>Parameters Cross validation :</b>\n",
    "- number of folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def avg_f1_score(y_test,y_pred):\n",
    "    pop_score = f1_score(y_test[199325], y_pred[:,0], average='macro',)\n",
    "    center_score = f1_score(y_test[199326], y_pred[:,1], average='macro')\n",
    "    return (pop_score+center_score)/2.0\n",
    "score = make_scorer(avg_f1_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(y[199325])\n",
    "y_enc = y \n",
    "y_enc[199325] = le.transform(y[199325])\n",
    "y_enc[199326] = y_enc[199326].astype('int') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## After Mid-term\n",
    "\n",
    "Using information from equivalence classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 180 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  3.6min\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=15, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=200, n_jobs=-1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# random.seed(18)\n",
    "rf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "rf_params = {\n",
    "    'n_estimators':[10,30,50,100,200,250],\n",
    "    'criterion': ('gini','entropy'),\n",
    "    'max_depth': [15,20,30,40,60],\n",
    "    'class_weight' : (None,'balanced','balanced_subsample')\n",
    "}\n",
    "gcv_rf = GridSearchCV(cv=4,estimator=rf,param_grid=rf_params,n_jobs=-1,scoring=score,verbose=1)\n",
    "gcv_rf.fit(X,y_enc)\n",
    "# scores = cross_val_score(clf, X, y, cv=5, scoring=score)\n",
    "\n",
    "print gcv_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best RFC\n",
    "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
    "            criterion='gini', max_depth=15, max_features='auto',\n",
    "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=200, n_jobs=-1, oob_score=False, random_state=0,\n",
    "            verbose=0, warm_start=False)\n",
    "            \n",
    "cv=4 <br>\n",
    "0.811905104099 0.0176607853188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811829641971\n"
     ]
    }
   ],
   "source": [
    "print gcv_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811905104099 0.0176607853188\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(gcv_rf.best_estimator_,X,y_enc, cv=4,n_jobs=-1,scoring=score,verbose=1)\n",
    "\n",
    "print scores.mean(),scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 180 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.4s\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   36.0s\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier(bootstrap=False, class_weight='balanced',\n",
      "           criterion='gini', max_depth=60, max_features='auto',\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=250, n_jobs=-1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "etc = ExtraTreesClassifier(n_jobs=-1)\n",
    "etc_params = {\n",
    "    'n_estimators':[10,30,50,100,200,250],\n",
    "    'criterion': ('gini','entropy'),\n",
    "    'max_depth': [15,20,30,40,60],\n",
    "    'class_weight' : (None,'balanced','balanced_subsample'),\n",
    "    \n",
    "}\n",
    "gcv_etc = GridSearchCV(cv=4,estimator=etc,param_grid=rf_params,n_jobs=-1,scoring=score,verbose=1)\n",
    "gcv_etc.fit(X,y_enc)\n",
    "# scores = cross_val_score(clf, X, y, cv=5, scoring=score)\n",
    "\n",
    "print gcv_etc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775486198935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777778749865 0.0137470677549\n"
     ]
    }
   ],
   "source": [
    "print gcv_etc.best_score_\n",
    "scores = cross_val_score(gcv_etc.best_estimator_,X,y_enc, cv=4,n_jobs=-1,scoring=score,verbose=1)\n",
    "\n",
    "print scores.mean(),scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 80 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   23.0s\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.1min\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=5, p=1,\n",
      "           weights='distance')\n"
     ]
    }
   ],
   "source": [
    "knn = KNN(n_jobs=-1)\n",
    "knn_params = {\n",
    "    'n_neighbors': [5,10,25,50,100],\n",
    "    'weights': ['uniform','distance'],\n",
    "    'algorithm': ('auto', 'ball_tree', 'kd_tree', 'brute'),\n",
    "    'p':[1,2]\n",
    "}\n",
    "gcv_knn = GridSearchCV(cv=4,estimator=knn,param_grid=knn_params,n_jobs=-1,scoring=score,verbose=1)\n",
    "gcv_knn.fit(X,y_enc)\n",
    "# scores = cross_val_score(clf, X, y, cv=5, scoring=score)\n",
    "\n",
    "print gcv_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.669801705702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66977957859 0.0151012433588\n"
     ]
    }
   ],
   "source": [
    "print gcv_knn.best_score_\n",
    "scores = cross_val_score(gcv_knn.best_estimator_,X,y_enc, cv=4,n_jobs=-1,scoring=score,verbose=1)\n",
    "\n",
    "print scores.mean(),scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "1) f1_score :  0.795271667071\n",
      "2) f1_score :  0.851374047154\n",
      "3) f1_score :  0.797495437569\n",
      "4) f1_score :  0.774835746723\n",
      "5) f1_score :  0.836501830552\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "print(kf)  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scores = []\n",
    "count =1\n",
    "for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_enc.iloc[train_index], y_enc.iloc[test_index]\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=150, max_depth=10, random_state=0, n_jobs=-1,class_weight=\"balanced_subsample\")\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "#     print y_pred[:,1]\n",
    "    pop_score = f1_score(y_test[199325], y_pred[:,0], average='macro')\n",
    "    center_score = f1_score(y_test[199326], y_pred[:,1], average='macro')\n",
    "    scores.append((pop_score+center_score)/2.0)\n",
    "    print str(count) +\") f1_score : \", scores[-1]\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average f-1 score is  0.811095745814\n"
     ]
    }
   ],
   "source": [
    "print \"The average f-1 score is \",sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"indices.pkl\", 'rb') as in_file:\n",
    "    indices = pkl.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"X_train_reduced.pkl\", 'rb') as in_file:\n",
    "    X = pkl.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"y.pkl\", 'rb') as in_file:\n",
    "    y = pkl.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Performing 5 fold cross validation on MLP Classifier\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "print(kf)  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scores = []\n",
    "count =1\n",
    "for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(256, 128), activation='logistic', #solver='lbfgs', #learning_rate='adaptive',\n",
    "                    verbose=False, tol=1e-5 ,max_iter=500, learning_rate_init=0.005\n",
    "#                     warm_start = True\n",
    "                   )\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    print count,\") f1_score : \", scores[-1]\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average f-1 score is  0.860651706532\n"
     ]
    }
   ],
   "source": [
    "print \"The average f-1 score is \",sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Data Flow pipeline\n",
    "\n",
    "Changing the approach\n",
    "    - Making a universal set of all distinct equivalence\n",
    "    - Given a population, we make a bit vector for all the equi_classes in that population\n",
    "    - Reducing the number of dimension\n",
    "    - Using that as a features to our last know best Classifier [MLP]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-904f329ee8b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mcur_eq_c\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mmaster_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folder_names = utilities.get_folder_names(\"./train/\")\n",
    "\n",
    "master_set = set()\n",
    "all_eq_c = {}\n",
    "count = 0\n",
    "for f in folder_names:\n",
    "    with open(\"./train/\" + f +\"/bias/aux_info/eq_classes.txt\") as eq_file:\n",
    "        eq_c = eq_file.read()\n",
    "\n",
    "    eq_c = eq_c.strip()\n",
    "    eq_c = eq_c.split(\"\\n\")\n",
    "    eq_c = eq_c[199326:]\n",
    "    \n",
    "    eq_c = np.array(eq_c)\n",
    "\n",
    "    cur_eq_c = {}\n",
    "    \n",
    "    try:\n",
    "        for i in range(len(eq_c)):\n",
    "            e = eq_c[i].split('\\t')\n",
    "            key = int(''.join(e[:-1]))\n",
    "            cur_eq_c[key] = int(e[-1])\n",
    "            master_set.add(key)\n",
    "    except Exception as err:\n",
    "        print err\n",
    "        print f,i\n",
    "    \n",
    "    all_eq_c[f] = cur_eq_c\n",
    "    count+=1\n",
    "    print count\n",
    "    gc.collect()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the new made sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl.dump(master_set,open('master_set.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('all_eq_classes.pkl','wb') as f:\n",
    "    pkl.dump(all_eq_c,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "tot_size = sys.getsizeof(all_eq_c.values())\n",
    "tot_size+= sum(map(sys.getsizeof,all_eq_c.itervalues()))\n",
    "print tot_size/(1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./master_set.pkl', 'rb') as f:\n",
    "    master_set = pkl.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./all_eq_classes.pkl', 'rb') as f:\n",
    "    all_eq_c = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in all_eq_c.keys():\n",
    "    with open('./all_equi_classes/'+k+'.pkl', 'wb') as out_file:\n",
    "        pkl.dump(all_eq_c[k], out_file)\n",
    "        del all_eq_c[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "0 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "2 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "3 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "4 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "5 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "6 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "7 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "8 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "9 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "10 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "11 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "12 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "13 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "14 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "15 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "16 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "17 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "18 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "19 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "20 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "21 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "22 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "23 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "24 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "25 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "26 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "27 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "28 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "29 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "30 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "31 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "32 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "33 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "34 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "35 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "36 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "37 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "38 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "39 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "40 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "41 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "42 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "43 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "44 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "45 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "46 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "47 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "48 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "49 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "50 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "51 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "52 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "53 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "54 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "55 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "56 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "57 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "58 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "59 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "60 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "61 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "62 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "63 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "64 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "65 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "66 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "67 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "68 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "69 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "70 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "71 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "72 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "73 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "74 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "75 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "76 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "77 folders done\n",
      "0\n",
      "100000\n",
      "200000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "78 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "79 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "80 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "81 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "82 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "83 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "84 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "85 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "86 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "87 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "88 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "89 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "90 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "91 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "92 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "93 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "94 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "95 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "96 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "97 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "98 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "99 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "100 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "101 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "102 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "103 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "104 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "105 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "106 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "107 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "108 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "109 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "110 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "111 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "112 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "113 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "114 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "115 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "116 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "117 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "118 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "119 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "120 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "121 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "122 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "123 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "124 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "125 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "126 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "127 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "128 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "129 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "130 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "131 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "132 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "133 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "134 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "135 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "136 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "137 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "138 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "139 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "140 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "141 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "142 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "143 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "144 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "145 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "146 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "147 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "148 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "149 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "150 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "151 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "152 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "153 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "154 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100000\n",
      "1200000\n",
      "155 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "156 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "157 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "158 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "159 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "160 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "161 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "162 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "163 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "164 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "165 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "166 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "167 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "168 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "169 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "170 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "171 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "172 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "173 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "174 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "175 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "176 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "177 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "178 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "179 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "180 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "181 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "182 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "183 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "184 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "185 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "186 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "187 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "188 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "189 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "190 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "191 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "192 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "193 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "194 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "195 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "196 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "197 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "198 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "199 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "200 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "201 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "202 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "203 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "204 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "205 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "206 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "207 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "208 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "209 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "210 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "211 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "212 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "213 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "214 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "215 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "216 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "217 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "218 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "219 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "220 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "221 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "222 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "223 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "224 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "225 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "226 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "227 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "228 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "229 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "230 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "231 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "232 folders done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "233 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "234 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "235 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "236 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "237 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "238 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "239 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "240 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "241 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "242 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "243 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "244 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "245 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "246 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "247 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "248 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "249 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "250 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "251 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "252 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "253 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "254 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "255 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "256 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "257 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "258 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "259 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "260 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "261 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "262 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "263 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "264 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "265 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "266 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "267 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "268 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "269 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "270 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "271 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "272 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "273 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "274 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "275 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "276 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "277 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "278 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "279 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "280 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "281 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "282 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "283 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "284 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "285 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "286 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "287 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "288 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "289 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "290 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "291 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "292 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "293 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "294 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "295 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "296 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "297 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "298 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "299 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "300 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "301 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "302 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "303 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "304 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "305 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "306 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "307 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "308 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "309 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "310 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "311 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "312 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "313 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "314 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "315 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "316 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "317 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "318 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "319 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "320 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "321 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "322 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "323 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "324 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "325 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "326 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "327 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "328 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "329 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "330 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "331 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "332 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "333 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "334 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "335 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "336 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "337 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "338 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "339 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "340 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "341 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "342 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "343 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "344 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "345 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "346 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "347 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "348 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "349 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "350 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "351 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "352 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "353 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "354 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "355 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "356 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "357 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "358 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "359 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "360 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "361 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "362 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "363 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "364 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "365 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "366 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "367 folders done\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "368 folders done\n"
     ]
    }
   ],
   "source": [
    "folder_names = utilities.get_folder_names(\"./train/\")\n",
    "master_set = list(master_set)\n",
    "\n",
    "for count, folder in enumerate(folder_names):\n",
    "#     with open('./eq_classes/'+folder+'.pkl') as acc_file:\n",
    "#         acc = pkl.load(acc_file)\n",
    "    acc = all_eq_c[folder]\n",
    "    \n",
    "    for i in range(len(master_set)):\n",
    "        cur = master_set[i]\n",
    "        if cur in acc:\n",
    "            acc[i] = acc[cur]\n",
    "            del acc[cur]\n",
    "    \n",
    "    with open('./eq_classes/'+folder+'.pkl', 'wb') as out_file:\n",
    "        pkl.dump(acc, out_file)\n",
    "    \n",
    "    gc.collect()\n",
    "    print count, \"folders done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder_names = utilities.get_folder_names(\"./train/\")\n",
    "train = pd.DataFrame(np.zeros((len(folder_names),len(master_set))), index=folder_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for folder in folder_names:\n",
    "    print count\n",
    "    count+=1\n",
    "    with open('./eq_classes/'+folder+'.pkl') as acc_file:\n",
    "        acc = pkl.load(acc_file)\n",
    "\n",
    "    classes = pd.Series(acc)\n",
    "    classes.fillna(0, inplace=True)\n",
    "    \n",
    "    train.loc[folder] = classes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.fillna(0, inplace=True)\n",
    "# train = train.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del master_set\n",
    "# del all_eq_c\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 369 entries, ERR188021 to ERR188482\n",
      "Columns: 1235737 entries, 0 to 1235736\n",
      "dtypes: float64(1235737)\n",
      "memory usage: 3.4+ GB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label = pd.read_csv('p1_train_pop_lab.csv', index_col=0)\n",
    "train = train.merge(label, left_index=True, right_index=True)\n",
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction and K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both labels together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train.drop(['population', 'sequencing_center'], axis=1)\n",
    "Y = train[['population', 'sequencing_center']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "1 ) f1_score :  0.854989614836\n",
      "2 ) f1_score :  0.900908119658\n",
      "3 ) f1_score :  0.897299836718\n",
      "4 ) f1_score :  0.886236990759\n",
      "5 ) f1_score :  0.893448828807\n",
      "The average f-1 score is  0.886576678156\n"
     ]
    }
   ],
   "source": [
    "## Performing 5 fold cross validation on MLP Classifier\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(Y.as_matrix())\n",
    "y = pd.DataFrame(y)\n",
    "\n",
    "\n",
    "print(kf)  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scores = []\n",
    "count =1\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    forest = ExtraTreesClassifier(n_estimators=250, n_jobs=-1, bootstrap=True, oob_score=True, verbose=0,\n",
    "                              random_state=0)\n",
    "\n",
    "    # using out-of-bag samples for testing generalization accuracy\n",
    "\n",
    "    forest.fit(X_train, y_train)\n",
    "    importances = forest.feature_importances_\n",
    "\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    \n",
    "    X_train = X_train.iloc[:, indices[:25000]]\n",
    "    X_test = X_test.iloc[:,indices[:25000]]\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(256, 128), activation='logistic', #solver='lbfgs', #learning_rate='adaptive',\n",
    "                    verbose=False, tol=1e-5 ,max_iter=500, learning_rate_init=0.005\n",
    "#                     warm_start = True\n",
    "                   )\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    print count,\") f1_score : \", scores[-1]\n",
    "    count+=1\n",
    "    \n",
    "print \"The average f-1 score is \",sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.87120638\n",
      "Iteration 2, loss = 1.38847487\n",
      "Iteration 3, loss = 1.13816334\n",
      "Iteration 4, loss = 0.90968955\n",
      "Iteration 5, loss = 0.73495297\n",
      "Iteration 6, loss = 0.60631613\n",
      "Iteration 7, loss = 0.51235473\n",
      "Iteration 8, loss = 0.42677230\n",
      "Iteration 9, loss = 0.35523898\n",
      "Iteration 10, loss = 0.29655610\n",
      "Iteration 11, loss = 0.25066097\n",
      "Iteration 12, loss = 0.20863976\n",
      "Iteration 13, loss = 0.17388955\n",
      "Iteration 14, loss = 0.14585426\n",
      "Iteration 15, loss = 0.12284672\n",
      "Iteration 16, loss = 0.10538645\n",
      "Iteration 17, loss = 0.08903583\n",
      "Iteration 18, loss = 0.07575138\n",
      "Iteration 19, loss = 0.06383354\n",
      "Iteration 20, loss = 0.05533300\n",
      "Iteration 21, loss = 0.04811277\n",
      "Iteration 22, loss = 0.04250060\n",
      "Iteration 23, loss = 0.03761373\n",
      "Iteration 24, loss = 0.03379968\n",
      "Iteration 25, loss = 0.03056328\n",
      "Iteration 26, loss = 0.02744636\n",
      "Iteration 27, loss = 0.02502891\n",
      "Iteration 28, loss = 0.02303075\n",
      "Iteration 29, loss = 0.02102925\n",
      "Iteration 30, loss = 0.01938685\n",
      "Iteration 31, loss = 0.01792729\n",
      "Iteration 32, loss = 0.01658241\n",
      "Iteration 33, loss = 0.01548193\n",
      "Iteration 34, loss = 0.01460216\n",
      "Iteration 35, loss = 0.01382282\n",
      "Iteration 36, loss = 0.01307231\n",
      "Iteration 37, loss = 0.01235631\n",
      "Iteration 38, loss = 0.01179094\n",
      "Iteration 39, loss = 0.01132455\n",
      "Iteration 40, loss = 0.01087719\n",
      "Iteration 41, loss = 0.01049177\n",
      "Iteration 42, loss = 0.01008161\n",
      "Iteration 43, loss = 0.00975255\n",
      "Iteration 44, loss = 0.00944362\n",
      "Iteration 45, loss = 0.00915979\n",
      "Iteration 46, loss = 0.00889088\n",
      "Iteration 47, loss = 0.00862336\n",
      "Iteration 48, loss = 0.00836594\n",
      "Iteration 49, loss = 0.00815919\n",
      "Iteration 50, loss = 0.00789894\n",
      "Iteration 51, loss = 0.00769118\n",
      "Iteration 52, loss = 0.00750800\n",
      "Iteration 53, loss = 0.00734287\n",
      "Iteration 54, loss = 0.00721356\n",
      "Iteration 55, loss = 0.00704980\n",
      "Iteration 56, loss = 0.00689790\n",
      "Iteration 57, loss = 0.00675227\n",
      "Iteration 58, loss = 0.00661963\n",
      "Iteration 59, loss = 0.00649934\n",
      "Iteration 60, loss = 0.00638684\n",
      "Iteration 61, loss = 0.00628438\n",
      "Iteration 62, loss = 0.00616125\n",
      "Iteration 63, loss = 0.00601338\n",
      "Iteration 64, loss = 0.00591446\n",
      "Iteration 65, loss = 0.00582157\n",
      "Iteration 66, loss = 0.00573029\n",
      "Iteration 67, loss = 0.00564641\n",
      "Iteration 68, loss = 0.00556552\n",
      "Iteration 69, loss = 0.00548660\n",
      "Iteration 70, loss = 0.00540879\n",
      "Iteration 71, loss = 0.00533561\n",
      "Iteration 72, loss = 0.00525804\n",
      "Iteration 73, loss = 0.00518744\n",
      "Iteration 74, loss = 0.00512446\n",
      "Iteration 75, loss = 0.00506529\n",
      "Iteration 76, loss = 0.00500451\n",
      "Iteration 77, loss = 0.00494094\n",
      "Iteration 78, loss = 0.00488243\n",
      "Iteration 79, loss = 0.00482500\n",
      "Iteration 80, loss = 0.00476766\n",
      "Iteration 81, loss = 0.00468793\n",
      "Iteration 82, loss = 0.00463602\n",
      "Iteration 83, loss = 0.00458038\n",
      "Iteration 84, loss = 0.00453021\n",
      "Iteration 85, loss = 0.00447705\n",
      "Iteration 86, loss = 0.00443356\n",
      "Iteration 87, loss = 0.00438836\n",
      "Iteration 88, loss = 0.00434533\n",
      "Iteration 89, loss = 0.00430354\n",
      "Iteration 90, loss = 0.00426371\n",
      "Iteration 91, loss = 0.00422180\n",
      "Iteration 92, loss = 0.00418163\n",
      "Iteration 93, loss = 0.00414556\n",
      "Iteration 94, loss = 0.00410958\n",
      "Iteration 95, loss = 0.00407126\n",
      "Iteration 96, loss = 0.00403381\n",
      "Iteration 97, loss = 0.00399767\n",
      "Iteration 98, loss = 0.00396401\n",
      "Iteration 99, loss = 0.00393168\n",
      "Iteration 100, loss = 0.00389962\n",
      "Iteration 101, loss = 0.00386810\n",
      "Iteration 102, loss = 0.00383568\n",
      "Iteration 103, loss = 0.00380601\n",
      "Iteration 104, loss = 0.00377836\n",
      "Iteration 105, loss = 0.00374872\n",
      "Iteration 106, loss = 0.00372114\n",
      "Iteration 107, loss = 0.00369309\n",
      "Iteration 108, loss = 0.00366783\n",
      "Iteration 109, loss = 0.00363958\n",
      "Iteration 110, loss = 0.00361297\n",
      "Iteration 111, loss = 0.00358842\n",
      "Iteration 112, loss = 0.00356343\n",
      "Iteration 113, loss = 0.00353918\n",
      "Iteration 114, loss = 0.00351636\n",
      "Iteration 115, loss = 0.00349193\n",
      "Iteration 116, loss = 0.00346851\n",
      "Iteration 117, loss = 0.00344733\n",
      "Iteration 118, loss = 0.00342217\n",
      "Iteration 119, loss = 0.00339952\n",
      "Iteration 120, loss = 0.00337850\n",
      "Iteration 121, loss = 0.00335684\n",
      "Iteration 122, loss = 0.00333478\n",
      "Iteration 123, loss = 0.00331455\n",
      "Iteration 124, loss = 0.00329444\n",
      "Iteration 125, loss = 0.00327545\n",
      "Iteration 126, loss = 0.00325634\n",
      "Iteration 127, loss = 0.00323768\n",
      "Iteration 128, loss = 0.00321932\n",
      "Iteration 129, loss = 0.00320106\n",
      "Iteration 130, loss = 0.00318297\n",
      "Iteration 131, loss = 0.00316509\n",
      "Iteration 132, loss = 0.00314751\n",
      "Iteration 133, loss = 0.00312988\n",
      "Iteration 134, loss = 0.00311275\n",
      "Iteration 135, loss = 0.00309554\n",
      "Iteration 136, loss = 0.00307835\n",
      "Iteration 137, loss = 0.00306292\n",
      "Iteration 138, loss = 0.00304726\n",
      "Iteration 139, loss = 0.00303080\n",
      "Iteration 140, loss = 0.00301494\n",
      "Iteration 141, loss = 0.00300042\n",
      "Iteration 142, loss = 0.00298493\n",
      "Iteration 143, loss = 0.00297037\n",
      "Iteration 144, loss = 0.00295554\n",
      "Iteration 145, loss = 0.00294071\n",
      "Iteration 146, loss = 0.00292648\n",
      "Iteration 147, loss = 0.00291270\n",
      "Iteration 148, loss = 0.00289817\n",
      "Iteration 149, loss = 0.00288286\n",
      "Iteration 150, loss = 0.00286896\n",
      "Iteration 151, loss = 0.00285550\n",
      "Iteration 152, loss = 0.00284213\n",
      "Iteration 153, loss = 0.00282906\n",
      "Iteration 154, loss = 0.00281553\n",
      "Iteration 155, loss = 0.00280257\n",
      "Iteration 156, loss = 0.00278975\n",
      "Iteration 157, loss = 0.00277733\n",
      "Iteration 158, loss = 0.00276429\n",
      "Iteration 159, loss = 0.00275259\n",
      "Iteration 160, loss = 0.00274039\n",
      "Iteration 161, loss = 0.00272814\n",
      "Iteration 162, loss = 0.00271565\n",
      "Iteration 163, loss = 0.00270422\n",
      "Iteration 164, loss = 0.00269219\n",
      "Iteration 165, loss = 0.00268093\n",
      "Iteration 166, loss = 0.00266936\n",
      "Iteration 167, loss = 0.00265808\n",
      "Iteration 168, loss = 0.00264711\n",
      "Iteration 169, loss = 0.00263612\n",
      "Iteration 170, loss = 0.00262495\n",
      "Iteration 171, loss = 0.00261438\n",
      "Iteration 172, loss = 0.00260400\n",
      "Iteration 173, loss = 0.00259363\n",
      "Iteration 174, loss = 0.00258351\n",
      "Iteration 175, loss = 0.00257320\n",
      "Iteration 176, loss = 0.00256284\n",
      "Iteration 177, loss = 0.00255271\n",
      "Iteration 178, loss = 0.00254231\n",
      "Iteration 179, loss = 0.00253271\n",
      "Iteration 180, loss = 0.00252309\n",
      "Iteration 181, loss = 0.00251361\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(256, 128), learning_rate='constant',\n",
       "       learning_rate_init=0.005, max_iter=500, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=1e-05, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "## using saved values for the important indices\n",
    "with open('both_indices.pkl') as f:\n",
    "    indices = pkl.load(f)\n",
    "\n",
    "indices = indices[:25000]\n",
    "\n",
    "X = X.iloc[:, indices[:25000]]\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(256, 128), activation='logistic', #solver='lbfgs', #learning_rate='adaptive',\n",
    "                verbose=True, tol=1e-5 ,max_iter=500, learning_rate_init=0.005\n",
    "                , warm_start = True\n",
    "               )\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('joint_model.pkl' , 'wb') as f:\n",
    "    pkl.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code to plot the feature importances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Plot the feature importances of the forest\n",
    "# count = 20\n",
    "# plt.figure(figsize=(16, 8))\n",
    "# # plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "# #        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "# plt.bar(range(count), importances[indices[:count]],\n",
    "#        color=\"r\", align=\"center\")\n",
    "\n",
    "# # plt.xticks(range(X_train.shape[1]), indices)\n",
    "# plt.xticks(range(count), indices[:count])\n",
    "# plt.xlim([-1, count])\n",
    "# plt.xlabel(\"Transcript Index\", fontsize=16)\n",
    "# plt.ylabel(\"Feature Importance\", fontsize=16)\n",
    "# # plt.xlim([-1, X_train.shape[1]])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train.drop(['population', 'sequencing_center'], axis=1)\n",
    "Y = train['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\softwares\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ) f1_score :  0.76015843591\n"
     ]
    }
   ],
   "source": [
    "## Performing 5 fold cross validation on MLP Classifier\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(Y.as_matrix())\n",
    "y = pd.DataFrame(y)\n",
    "\n",
    "\n",
    "print(kf)  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scores = []\n",
    "count =1\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    forest = ExtraTreesClassifier(n_estimators=250, n_jobs=-1, bootstrap=True, oob_score=True, verbose=0,\n",
    "                              random_state=0)\n",
    "\n",
    "    # using out-of-bag samples for testing generalization accuracy\n",
    "\n",
    "    forest.fit(X_train, y_train)\n",
    "    importances = forest.feature_importances_\n",
    "\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    ## choosing the top 25000 features\n",
    "    X_train = X_train.iloc[:, indices[:25000]]\n",
    "    X_test = X_test.iloc[:,indices[:25000]]\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(256, 128), activation='logistic', #solver='lbfgs', #learning_rate='adaptive',\n",
    "                    verbose=False, tol=1e-5 ,max_iter=500, learning_rate_init=0.005\n",
    "#                     warm_start = True\n",
    "                   )\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    print count,\") f1_score : \", scores[-1]\n",
    "    count+=1\n",
    "\n",
    "print \"The average f-1 score is \",sum(scores)/len(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.79976382\n",
      "Iteration 2, loss = 1.34133044\n",
      "Iteration 3, loss = 1.02624009\n",
      "Iteration 4, loss = 0.78335021\n",
      "Iteration 5, loss = 0.60021750\n",
      "Iteration 6, loss = 0.45742585\n",
      "Iteration 7, loss = 0.34832132\n",
      "Iteration 8, loss = 0.26588459\n",
      "Iteration 9, loss = 0.20587731\n",
      "Iteration 10, loss = 0.16064874\n",
      "Iteration 11, loss = 0.12439996\n",
      "Iteration 12, loss = 0.09642873\n",
      "Iteration 13, loss = 0.07626724\n",
      "Iteration 14, loss = 0.06114059\n",
      "Iteration 15, loss = 0.05013843\n",
      "Iteration 16, loss = 0.04152678\n",
      "Iteration 17, loss = 0.03538719\n",
      "Iteration 18, loss = 0.02984724\n",
      "Iteration 19, loss = 0.02571255\n",
      "Iteration 20, loss = 0.02224629\n",
      "Iteration 21, loss = 0.01952186\n",
      "Iteration 22, loss = 0.01755661\n",
      "Iteration 23, loss = 0.01592026\n",
      "Iteration 24, loss = 0.01440066\n",
      "Iteration 25, loss = 0.01324120\n",
      "Iteration 26, loss = 0.01236373\n",
      "Iteration 27, loss = 0.01161622\n",
      "Iteration 28, loss = 0.01096456\n",
      "Iteration 29, loss = 0.01033994\n",
      "Iteration 30, loss = 0.00987673\n",
      "Iteration 31, loss = 0.00943899\n",
      "Iteration 32, loss = 0.00904068\n",
      "Iteration 33, loss = 0.00870037\n",
      "Iteration 34, loss = 0.00837612\n",
      "Iteration 35, loss = 0.00805079\n",
      "Iteration 36, loss = 0.00777945\n",
      "Iteration 37, loss = 0.00754463\n",
      "Iteration 38, loss = 0.00732397\n",
      "Iteration 39, loss = 0.00711042\n",
      "Iteration 40, loss = 0.00693416\n",
      "Iteration 41, loss = 0.00676847\n",
      "Iteration 42, loss = 0.00660321\n",
      "Iteration 43, loss = 0.00645294\n",
      "Iteration 44, loss = 0.00631744\n",
      "Iteration 45, loss = 0.00618260\n",
      "Iteration 46, loss = 0.00606320\n",
      "Iteration 47, loss = 0.00595014\n",
      "Iteration 48, loss = 0.00584511\n",
      "Iteration 49, loss = 0.00573906\n",
      "Iteration 50, loss = 0.00563935\n",
      "Iteration 51, loss = 0.00553749\n",
      "Iteration 52, loss = 0.00544590\n",
      "Iteration 53, loss = 0.00536437\n",
      "Iteration 54, loss = 0.00528203\n",
      "Iteration 55, loss = 0.00519700\n",
      "Iteration 56, loss = 0.00511592\n",
      "Iteration 57, loss = 0.00504190\n",
      "Iteration 58, loss = 0.00496540\n",
      "Iteration 59, loss = 0.00489278\n",
      "Iteration 60, loss = 0.00482472\n",
      "Iteration 61, loss = 0.00476148\n",
      "Iteration 62, loss = 0.00469727\n",
      "Iteration 63, loss = 0.00463975\n",
      "Iteration 64, loss = 0.00458433\n",
      "Iteration 65, loss = 0.00452810\n",
      "Iteration 66, loss = 0.00447762\n",
      "Iteration 67, loss = 0.00442688\n",
      "Iteration 68, loss = 0.00437589\n",
      "Iteration 69, loss = 0.00433150\n",
      "Iteration 70, loss = 0.00428181\n",
      "Iteration 71, loss = 0.00423540\n",
      "Iteration 72, loss = 0.00419072\n",
      "Iteration 73, loss = 0.00414687\n",
      "Iteration 74, loss = 0.00410412\n",
      "Iteration 75, loss = 0.00406148\n",
      "Iteration 76, loss = 0.00402179\n",
      "Iteration 77, loss = 0.00398507\n",
      "Iteration 78, loss = 0.00394590\n",
      "Iteration 79, loss = 0.00390193\n",
      "Iteration 80, loss = 0.00386630\n",
      "Iteration 81, loss = 0.00383174\n",
      "Iteration 82, loss = 0.00379368\n",
      "Iteration 83, loss = 0.00375907\n",
      "Iteration 84, loss = 0.00372131\n",
      "Iteration 85, loss = 0.00368960\n",
      "Iteration 86, loss = 0.00365866\n",
      "Iteration 87, loss = 0.00362808\n",
      "Iteration 88, loss = 0.00359703\n",
      "Iteration 89, loss = 0.00356814\n",
      "Iteration 90, loss = 0.00354010\n",
      "Iteration 91, loss = 0.00351214\n",
      "Iteration 92, loss = 0.00348600\n",
      "Iteration 93, loss = 0.00345914\n",
      "Iteration 94, loss = 0.00343327\n",
      "Iteration 95, loss = 0.00340799\n",
      "Iteration 96, loss = 0.00338294\n",
      "Iteration 97, loss = 0.00335891\n",
      "Iteration 98, loss = 0.00333519\n",
      "Iteration 99, loss = 0.00331101\n",
      "Iteration 100, loss = 0.00328853\n",
      "Iteration 101, loss = 0.00326557\n",
      "Iteration 102, loss = 0.00324340\n",
      "Iteration 103, loss = 0.00322136\n",
      "Iteration 104, loss = 0.00319924\n",
      "Iteration 105, loss = 0.00317810\n",
      "Iteration 106, loss = 0.00315786\n",
      "Iteration 107, loss = 0.00313807\n",
      "Iteration 108, loss = 0.00311743\n",
      "Iteration 109, loss = 0.00309829\n",
      "Iteration 110, loss = 0.00307868\n",
      "Iteration 111, loss = 0.00305935\n",
      "Iteration 112, loss = 0.00304142\n",
      "Iteration 113, loss = 0.00302294\n",
      "Iteration 114, loss = 0.00300550\n",
      "Iteration 115, loss = 0.00298783\n",
      "Iteration 116, loss = 0.00297009\n",
      "Iteration 117, loss = 0.00295323\n",
      "Iteration 118, loss = 0.00293586\n",
      "Iteration 119, loss = 0.00291903\n",
      "Iteration 120, loss = 0.00290250\n",
      "Iteration 121, loss = 0.00288604\n",
      "Iteration 122, loss = 0.00286968\n",
      "Iteration 123, loss = 0.00285366\n",
      "Iteration 124, loss = 0.00283818\n",
      "Iteration 125, loss = 0.00282228\n",
      "Iteration 126, loss = 0.00280737\n",
      "Iteration 127, loss = 0.00279259\n",
      "Iteration 128, loss = 0.00277786\n",
      "Iteration 129, loss = 0.00276358\n",
      "Iteration 130, loss = 0.00274887\n",
      "Iteration 131, loss = 0.00273449\n",
      "Iteration 132, loss = 0.00272047\n",
      "Iteration 133, loss = 0.00270705\n",
      "Iteration 134, loss = 0.00269369\n",
      "Iteration 135, loss = 0.00268047\n",
      "Iteration 136, loss = 0.00266713\n",
      "Iteration 137, loss = 0.00265439\n",
      "Iteration 138, loss = 0.00264118\n",
      "Iteration 139, loss = 0.00262841\n",
      "Iteration 140, loss = 0.00261595\n",
      "Iteration 141, loss = 0.00260348\n",
      "Iteration 142, loss = 0.00259114\n",
      "Iteration 143, loss = 0.00257938\n",
      "Iteration 144, loss = 0.00256721\n",
      "Iteration 145, loss = 0.00255532\n",
      "Iteration 146, loss = 0.00254371\n",
      "Iteration 147, loss = 0.00253250\n",
      "Iteration 148, loss = 0.00252095\n",
      "Iteration 149, loss = 0.00250972\n",
      "Iteration 150, loss = 0.00249803\n",
      "Iteration 151, loss = 0.00248675\n",
      "Iteration 152, loss = 0.00247606\n",
      "Iteration 153, loss = 0.00246485\n",
      "Iteration 154, loss = 0.00245347\n",
      "Iteration 155, loss = 0.00244309\n",
      "Iteration 156, loss = 0.00243299\n",
      "Iteration 157, loss = 0.00242228\n",
      "Iteration 158, loss = 0.00241237\n",
      "Iteration 159, loss = 0.00240244\n",
      "Iteration 160, loss = 0.00239230\n",
      "Iteration 161, loss = 0.00238255\n",
      "Iteration 162, loss = 0.00237272\n",
      "Iteration 163, loss = 0.00236344\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(256, 128), learning_rate='constant',\n",
       "       learning_rate_init=0.005, max_iter=500, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=1e-05, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "with open('population_indices.pkl') as f:\n",
    "    indices = pkl.load(f)\n",
    "\n",
    "indices = indices[:25000]\n",
    "\n",
    "X = X.iloc[:, indices[:25000]]\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(256, 128), activation='logistic', #solver='lbfgs', #learning_rate='adaptive',\n",
    "                verbose=True, tol=1e-5 ,max_iter=500, learning_rate_init=0.005\n",
    "                , warm_start = True\n",
    "               )\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('population_model.pkl' , 'wb') as f:\n",
    "    pkl.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For sequencing center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train.drop(['population', 'sequencing_center'], axis=1)\n",
    "y = train['sequencing_center']\n",
    "# with open('X_reduced.pkl') as f:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "1 ) f1_score :  0.929378894415\n",
      "2 ) f1_score :  0.979487179487\n",
      "3 ) f1_score :  0.963213044131\n",
      "4 ) f1_score :  0.94509695345\n",
      "5 ) f1_score :  0.856975523656\n",
      "The average f-1 score is  0.934830319028\n"
     ]
    }
   ],
   "source": [
    "## Performing 5 fold cross validation on MLP Classifier\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# y = mlb.fit_transform(Y.as_matrix())\n",
    "# y = pd.DataFrame(y)\n",
    "\n",
    "\n",
    "print(kf)  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scores = []\n",
    "count = 1\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    forest = ExtraTreesClassifier(n_estimators=250, bootstrap=True, oob_score=True, verbose=0,\n",
    "                              random_state=0)\n",
    "\n",
    "    # using out-of-bag samples for testing generalization accuracy\n",
    "\n",
    "    forest.fit(X_train, y_train)\n",
    "    importances = forest.feature_importances_\n",
    "\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    ## choosing the top 25000 features\n",
    "    X_train = X_train.iloc[:, indices[:25000]]\n",
    "    X_test = X_test.iloc[:,indices[:25000]]\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(256, 128), activation='logistic', #solver='lbfgs', #learning_rate='adaptive',\n",
    "                    verbose=False, tol=1e-5 ,max_iter=500, learning_rate_init=0.005\n",
    "#                     warm_start = True\n",
    "                   )\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    print count,\") f1_score : \", scores[-1]\n",
    "    count+=1\n",
    "\n",
    "print \"The average f-1 score is \",sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can definitely improve the f1 score and accuracy.\n",
    "However, the only limitation is of memory.\n",
    "Since, fitting the entire data structure and other variables in RAM \n",
    "along with the overhead of hashing was giving memory errors.\n",
    "If we can try to run this on a more powerful machine, it will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.78659288\n",
      "Iteration 2, loss = 1.29142741\n",
      "Iteration 3, loss = 0.98892950\n",
      "Iteration 4, loss = 0.72185731\n",
      "Iteration 5, loss = 0.54677938\n",
      "Iteration 6, loss = 0.42454023\n",
      "Iteration 7, loss = 0.32707046\n",
      "Iteration 8, loss = 0.24638604\n",
      "Iteration 9, loss = 0.19025798\n",
      "Iteration 10, loss = 0.15039883\n",
      "Iteration 11, loss = 0.12065756\n",
      "Iteration 12, loss = 0.09586622\n",
      "Iteration 13, loss = 0.07751999\n",
      "Iteration 14, loss = 0.06257380\n",
      "Iteration 15, loss = 0.05075592\n",
      "Iteration 16, loss = 0.04260496\n",
      "Iteration 17, loss = 0.03594923\n",
      "Iteration 18, loss = 0.03087076\n",
      "Iteration 19, loss = 0.02624691\n",
      "Iteration 20, loss = 0.02277227\n",
      "Iteration 21, loss = 0.02019520\n",
      "Iteration 22, loss = 0.01790271\n",
      "Iteration 23, loss = 0.01625830\n",
      "Iteration 24, loss = 0.01474072\n",
      "Iteration 25, loss = 0.01358695\n",
      "Iteration 26, loss = 0.01258689\n",
      "Iteration 27, loss = 0.01172917\n",
      "Iteration 28, loss = 0.01103182\n",
      "Iteration 29, loss = 0.01040501\n",
      "Iteration 30, loss = 0.00986482\n",
      "Iteration 31, loss = 0.00936750\n",
      "Iteration 32, loss = 0.00895916\n",
      "Iteration 33, loss = 0.00859819\n",
      "Iteration 34, loss = 0.00828977\n",
      "Iteration 35, loss = 0.00801003\n",
      "Iteration 36, loss = 0.00770703\n",
      "Iteration 37, loss = 0.00746148\n",
      "Iteration 38, loss = 0.00722192\n",
      "Iteration 39, loss = 0.00701041\n",
      "Iteration 40, loss = 0.00681766\n",
      "Iteration 41, loss = 0.00664504\n",
      "Iteration 42, loss = 0.00648799\n",
      "Iteration 43, loss = 0.00633813\n",
      "Iteration 44, loss = 0.00619816\n",
      "Iteration 45, loss = 0.00606838\n",
      "Iteration 46, loss = 0.00594774\n",
      "Iteration 47, loss = 0.00583803\n",
      "Iteration 48, loss = 0.00572781\n",
      "Iteration 49, loss = 0.00562417\n",
      "Iteration 50, loss = 0.00551824\n",
      "Iteration 51, loss = 0.00542319\n",
      "Iteration 52, loss = 0.00533084\n",
      "Iteration 53, loss = 0.00525052\n",
      "Iteration 54, loss = 0.00516512\n",
      "Iteration 55, loss = 0.00508322\n",
      "Iteration 56, loss = 0.00500821\n",
      "Iteration 57, loss = 0.00493429\n",
      "Iteration 58, loss = 0.00485695\n",
      "Iteration 59, loss = 0.00479256\n",
      "Iteration 60, loss = 0.00472582\n",
      "Iteration 61, loss = 0.00466173\n",
      "Iteration 62, loss = 0.00459942\n",
      "Iteration 63, loss = 0.00454422\n",
      "Iteration 64, loss = 0.00448497\n",
      "Iteration 65, loss = 0.00442631\n",
      "Iteration 66, loss = 0.00437472\n",
      "Iteration 67, loss = 0.00432193\n",
      "Iteration 68, loss = 0.00426973\n",
      "Iteration 69, loss = 0.00421979\n",
      "Iteration 70, loss = 0.00417467\n",
      "Iteration 71, loss = 0.00412723\n",
      "Iteration 72, loss = 0.00408340\n",
      "Iteration 73, loss = 0.00403898\n",
      "Iteration 74, loss = 0.00399701\n",
      "Iteration 75, loss = 0.00395496\n",
      "Iteration 76, loss = 0.00391602\n",
      "Iteration 77, loss = 0.00387598\n",
      "Iteration 78, loss = 0.00383930\n",
      "Iteration 79, loss = 0.00380227\n",
      "Iteration 80, loss = 0.00376560\n",
      "Iteration 81, loss = 0.00373154\n",
      "Iteration 82, loss = 0.00369710\n",
      "Iteration 83, loss = 0.00366273\n",
      "Iteration 84, loss = 0.00362983\n",
      "Iteration 85, loss = 0.00359850\n",
      "Iteration 86, loss = 0.00356549\n",
      "Iteration 87, loss = 0.00353562\n",
      "Iteration 88, loss = 0.00350506\n",
      "Iteration 89, loss = 0.00347503\n",
      "Iteration 90, loss = 0.00344648\n",
      "Iteration 91, loss = 0.00341802\n",
      "Iteration 92, loss = 0.00339128\n",
      "Iteration 93, loss = 0.00336325\n",
      "Iteration 94, loss = 0.00333721\n",
      "Iteration 95, loss = 0.00331203\n",
      "Iteration 96, loss = 0.00328692\n",
      "Iteration 97, loss = 0.00326169\n",
      "Iteration 98, loss = 0.00323688\n",
      "Iteration 99, loss = 0.00321259\n",
      "Iteration 100, loss = 0.00318972\n",
      "Iteration 101, loss = 0.00316671\n",
      "Iteration 102, loss = 0.00314487\n",
      "Iteration 103, loss = 0.00312229\n",
      "Iteration 104, loss = 0.00310074\n",
      "Iteration 105, loss = 0.00307983\n",
      "Iteration 106, loss = 0.00305908\n",
      "Iteration 107, loss = 0.00303723\n",
      "Iteration 108, loss = 0.00301658\n",
      "Iteration 109, loss = 0.00299745\n",
      "Iteration 110, loss = 0.00297882\n",
      "Iteration 111, loss = 0.00295857\n",
      "Iteration 112, loss = 0.00294065\n",
      "Iteration 113, loss = 0.00292227\n",
      "Iteration 114, loss = 0.00290413\n",
      "Iteration 115, loss = 0.00288691\n",
      "Iteration 116, loss = 0.00286986\n",
      "Iteration 117, loss = 0.00285174\n",
      "Iteration 118, loss = 0.00283556\n",
      "Iteration 119, loss = 0.00281852\n",
      "Iteration 120, loss = 0.00280259\n",
      "Iteration 121, loss = 0.00278633\n",
      "Iteration 122, loss = 0.00276971\n",
      "Iteration 123, loss = 0.00275441\n",
      "Iteration 124, loss = 0.00273924\n",
      "Iteration 125, loss = 0.00272388\n",
      "Iteration 126, loss = 0.00270794\n",
      "Iteration 127, loss = 0.00269322\n",
      "Iteration 128, loss = 0.00267817\n",
      "Iteration 129, loss = 0.00266290\n",
      "Iteration 130, loss = 0.00264872\n",
      "Iteration 131, loss = 0.00263475\n",
      "Iteration 132, loss = 0.00262060\n",
      "Iteration 133, loss = 0.00260740\n",
      "Iteration 134, loss = 0.00259382\n",
      "Iteration 135, loss = 0.00258091\n",
      "Iteration 136, loss = 0.00256767\n",
      "Iteration 137, loss = 0.00255424\n",
      "Iteration 138, loss = 0.00254199\n",
      "Iteration 139, loss = 0.00252902\n",
      "Iteration 140, loss = 0.00251689\n",
      "Iteration 141, loss = 0.00250432\n",
      "Iteration 142, loss = 0.00249213\n",
      "Iteration 143, loss = 0.00247914\n",
      "Iteration 144, loss = 0.00246694\n",
      "Iteration 145, loss = 0.00245572\n",
      "Iteration 146, loss = 0.00244426\n",
      "Iteration 147, loss = 0.00243271\n",
      "Iteration 148, loss = 0.00242120\n",
      "Iteration 149, loss = 0.00240966\n",
      "Iteration 150, loss = 0.00239901\n",
      "Iteration 151, loss = 0.00238799\n",
      "Iteration 152, loss = 0.00237706\n",
      "Iteration 153, loss = 0.00236652\n",
      "Iteration 154, loss = 0.00235639\n",
      "Iteration 155, loss = 0.00234575\n",
      "Iteration 156, loss = 0.00233553\n",
      "Iteration 157, loss = 0.00232552\n",
      "Iteration 158, loss = 0.00231554\n",
      "Iteration 159, loss = 0.00230557\n",
      "Iteration 160, loss = 0.00229592\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(256, 128), learning_rate='constant',\n",
       "       learning_rate_init=0.005, max_iter=500, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=1e-05, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "with open('sequencing_indices.pkl') as f:\n",
    "    indices = pkl.load(f)\n",
    "\n",
    "indices = indices[:25000]\n",
    "\n",
    "X = X.iloc[:, indices[:25000]]\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(256, 128), activation='logistic', #solver='lbfgs', #learning_rate='adaptive',\n",
    "                verbose=True, tol=1e-5 ,max_iter=500, learning_rate_init=0.005\n",
    "                , warm_start = True\n",
    "               )\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('sequencing_model.pkl' , 'wb') as f:\n",
    "    pkl.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting feature indices to feature names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('both_indices.pkl') as f:\n",
    "    indices = pkl.load(f)\n",
    "\n",
    "indices = indices[:25000]\n",
    "\n",
    "ma = list(master_set)\n",
    "multi_features = []\n",
    "for i in indices:\n",
    "    multi_features.append(ma[i])\n",
    "    \n",
    "with open('multi_features.pkl','wb') as f:\n",
    "    pkl.dump(multi_features,f)\n",
    "    \n",
    "\n",
    "\n",
    "with open('population_indices.pkl') as f:\n",
    "    pop_indices = pkl.load(f)   \n",
    "    pop_indices  = pop_indices[:25000]\n",
    "\n",
    "pop_features = []\n",
    "for i in pop_indices:\n",
    "    pop_features.append(ma[i])\n",
    "    \n",
    "with open('pop_features.pkl','wb') as f:\n",
    "    pkl.dump(pop_features,f)\n",
    "    \n",
    "    \n",
    "    \n",
    "with open('sequencing_indices.pkl') as f:\n",
    "    seq_indices = pkl.load(f)   \n",
    "    seq_indices  = seq_indices[:25000]\n",
    "\n",
    "seq_features = []\n",
    "for i in seq_indices:\n",
    "    seq_features.append(ma[i])\n",
    "    \n",
    "with open('seq_features.pkl','wb') as f:\n",
    "    pkl.dump(seq_features,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scalers = {}\n",
    "with open('joint_scalar.pkl') as f:\n",
    "    multi = pkl.load(f)\n",
    "\n",
    "all_scalers['multi_scaler'] = multi\n",
    " \n",
    "\n",
    "with open('population_scalar.pkl') as f:\n",
    "    pop = pkl.load(f)   \n",
    "\n",
    "all_scalers['pop_scaler'] = pop\n",
    "    \n",
    "with open('sequencing_scalar.pkl') as f:\n",
    "    seq = pkl.load(f)   \n",
    "\n",
    "all_scalers['seq_scaler'] = seq\n",
    "with open('all_scalers.pkl','wb') as f:\n",
    "    pkl.dump(all_scalers,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_scalers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
