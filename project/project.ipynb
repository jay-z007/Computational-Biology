{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Project 1 - Phenotypic Prediction from Transcriptomic Features\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "import matplotlib.pyplot as plt\n",
    "import utilities\n",
    "import os\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Extracted the TPM value for each Accession folder and stored in the 'tpm_train.pkl' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tpm_train.pkl\", 'rb') as input_file:\n",
    "    data = pkl.load(input_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)    \n",
    "data.set_index(0, inplace=True)\n",
    "\n",
    "labels = data.iloc[:,-2:]\n",
    "\n",
    "data.columns = [str(i) for i in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['199325','199326'], axis=1)\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>199325</th>\n",
       "      <th>199326</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>369</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>FIN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>77</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       199325 199326\n",
       "count     369    369\n",
       "unique      5      7\n",
       "top       FIN      1\n",
       "freq       77     90"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>199315</th>\n",
       "      <th>199316</th>\n",
       "      <th>199317</th>\n",
       "      <th>199318</th>\n",
       "      <th>199319</th>\n",
       "      <th>199320</th>\n",
       "      <th>199321</th>\n",
       "      <th>199322</th>\n",
       "      <th>199323</th>\n",
       "      <th>199324</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ERR188408</th>\n",
       "      <td>0.234074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.67617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.424268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8344.730469</td>\n",
       "      <td>47.279900</td>\n",
       "      <td>67.131699</td>\n",
       "      <td>309.765015</td>\n",
       "      <td>3487.449951</td>\n",
       "      <td>8528.700195</td>\n",
       "      <td>205.423004</td>\n",
       "      <td>5413.819824</td>\n",
       "      <td>423.902008</td>\n",
       "      <td>3361.919922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR188348</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.98881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7749.709961</td>\n",
       "      <td>18.325001</td>\n",
       "      <td>33.006401</td>\n",
       "      <td>23.371000</td>\n",
       "      <td>2073.770020</td>\n",
       "      <td>5866.830078</td>\n",
       "      <td>148.636002</td>\n",
       "      <td>4562.600098</td>\n",
       "      <td>360.488007</td>\n",
       "      <td>1861.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR188021</th>\n",
       "      <td>0.221792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.42060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.080040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8584.839844</td>\n",
       "      <td>35.289902</td>\n",
       "      <td>36.760399</td>\n",
       "      <td>92.426003</td>\n",
       "      <td>3532.689941</td>\n",
       "      <td>5837.020020</td>\n",
       "      <td>299.964996</td>\n",
       "      <td>3237.989990</td>\n",
       "      <td>85.903198</td>\n",
       "      <td>2026.969971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR188289</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.29350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.404072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7107.479980</td>\n",
       "      <td>27.253099</td>\n",
       "      <td>62.682098</td>\n",
       "      <td>87.815498</td>\n",
       "      <td>2366.439941</td>\n",
       "      <td>6055.959961</td>\n",
       "      <td>121.125000</td>\n",
       "      <td>2903.419922</td>\n",
       "      <td>459.035004</td>\n",
       "      <td>1813.839966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR188262</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.680980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10734.000000</td>\n",
       "      <td>28.609100</td>\n",
       "      <td>79.920303</td>\n",
       "      <td>103.341003</td>\n",
       "      <td>3527.360107</td>\n",
       "      <td>6186.930176</td>\n",
       "      <td>74.823898</td>\n",
       "      <td>5829.339844</td>\n",
       "      <td>119.750000</td>\n",
       "      <td>2343.639893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199324 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1    2        3    4    5    6    7    8         9   10  \\\n",
       "0                                                                           \n",
       "ERR188408  0.234074  0.0  3.67617  0.0  0.0  0.0  0.0  0.0  0.424268  0.0   \n",
       "ERR188348  0.000000  0.0  1.98881  0.0  0.0  0.0  0.0  0.0  0.137385  0.0   \n",
       "ERR188021  0.221792  0.0  5.42060  0.0  0.0  0.0  0.0  0.0  1.080040  0.0   \n",
       "ERR188289  0.000000  0.0  8.29350  0.0  0.0  0.0  0.0  0.0  0.404072  0.0   \n",
       "ERR188262  0.016667  0.0  2.00487  0.0  0.0  0.0  0.0  0.0  0.680980  0.0   \n",
       "\n",
       "              ...             199315     199316     199317      199318  \\\n",
       "0             ...                                                        \n",
       "ERR188408     ...        8344.730469  47.279900  67.131699  309.765015   \n",
       "ERR188348     ...        7749.709961  18.325001  33.006401   23.371000   \n",
       "ERR188021     ...        8584.839844  35.289902  36.760399   92.426003   \n",
       "ERR188289     ...        7107.479980  27.253099  62.682098   87.815498   \n",
       "ERR188262     ...       10734.000000  28.609100  79.920303  103.341003   \n",
       "\n",
       "                199319       199320      199321       199322      199323  \\\n",
       "0                                                                          \n",
       "ERR188408  3487.449951  8528.700195  205.423004  5413.819824  423.902008   \n",
       "ERR188348  2073.770020  5866.830078  148.636002  4562.600098  360.488007   \n",
       "ERR188021  3532.689941  5837.020020  299.964996  3237.989990   85.903198   \n",
       "ERR188289  2366.439941  6055.959961  121.125000  2903.419922  459.035004   \n",
       "ERR188262  3527.360107  6186.930176   74.823898  5829.339844  119.750000   \n",
       "\n",
       "                199324  \n",
       "0                       \n",
       "ERR188408  3361.919922  \n",
       "ERR188348  1861.000000  \n",
       "ERR188021  2026.969971  \n",
       "ERR188289  1813.839966  \n",
       "ERR188262  2343.639893  \n",
       "\n",
       "[5 rows x 199324 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>199325</th>\n",
       "      <th>199326</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ERR188023</th>\n",
       "      <td>FIN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR188022</th>\n",
       "      <td>CEU</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR188356</th>\n",
       "      <td>TSI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR188079</th>\n",
       "      <td>TSI</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR188032</th>\n",
       "      <td>CEU</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          199325 199326\n",
       "0                      \n",
       "ERR188023    FIN      2\n",
       "ERR188022    CEU      1\n",
       "ERR188356    TSI      1\n",
       "ERR188079    TSI      4\n",
       "ERR188032    CEU      7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Trying ExtraTreesClassifier on TPM for finding Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 146538 (0.001027)\n",
      "2. feature 26680 (0.000885)\n",
      "3. feature 146526 (0.000839)\n",
      "4. feature 27152 (0.000744)\n",
      "5. feature 2601 (0.000743)\n",
      "6. feature 188191 (0.000739)\n",
      "7. feature 164230 (0.000730)\n",
      "8. feature 105409 (0.000677)\n",
      "9. feature 86816 (0.000675)\n",
      "10. feature 168691 (0.000645)\n",
      "11. feature 94604 (0.000636)\n",
      "12. feature 157375 (0.000631)\n",
      "13. feature 35348 (0.000617)\n",
      "14. feature 175821 (0.000613)\n",
      "15. feature 64611 (0.000608)\n"
     ]
    }
   ],
   "source": [
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250, n_jobs=-1, bootstrap=True, oob_score=True, verbose=1,\n",
    "                              random_state=0)\n",
    "\n",
    "# using out-of-bag samples for testing generalization accuracy\n",
    "\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1])[:15]:\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8sAAAHoCAYAAAB+Vn0eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noTOupqYAAAACSURBVEglD1+s8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb91fe10290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the feature importances of the forest\n",
    "count = 20\n",
    "plt.figure(figsize=(16, 8))\n",
    "# plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "#        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.bar(range(count), importances[indices[:count]],\n",
    "       color=\"r\", align=\"center\")\n",
    "\n",
    "# plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xticks(range(count), indices[:count])\n",
    "plt.xlim([-1, count])\n",
    "plt.xlabel(\"Transcript Index\", fontsize=16)\n",
    "plt.ylabel(\"Feature Importance\", fontsize=16)\n",
    "# plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dumping the variables to pickle\n",
    "To save processing time for future runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"indices.pkl\"):\n",
    "    with open(\"indices.pkl\", 'wb') as out:\n",
    "        pkl.dump(indices, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"X.pkl\"):\n",
    "    with open(\"X.pkl\", 'wb') as out:\n",
    "        pkl.dump(X, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"y.pkl\"):\n",
    "    with open(\"y.pkl\", 'wb') as out:\n",
    "        pkl.dump(y, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.iloc[:, indices[:10000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"X_train_reduced.pkl\"):\n",
    "    with open(\"X_train_reduced.pkl\", 'wb') as out:\n",
    "        pkl.dump(X, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Implementing PCA on the selected important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=512)\n",
    "X_new = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 369)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting observation, after trying PCA we get a worse answer. This is because the fact that we have very less data to train on.<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation on RandomForestClassifier\n",
    "<br>\n",
    "<b>Parameters for the Forest :</b>\n",
    "- Number of trees = 200\n",
    "- Max depth of a tree - 60\n",
    "\n",
    "<b>Parameters Cross validation :</b>\n",
    "- number of folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def avg_f1_score(y_test,y_pred):\n",
    "    pop_score = f1_score(y_test[199325], y_pred[:,0], average='macro',)\n",
    "    center_score = f1_score(y_test[199326], y_pred[:,1], average='macro')\n",
    "    return (pop_score+center_score)/2.0\n",
    "score = make_scorer(avg_f1_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(y[199325])\n",
    "y_enc = y \n",
    "y_enc[199325] = le.transform(y[199325])\n",
    "y_enc[199326] = y_enc[199326].astype('int') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 180 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  3.6min\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=15, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=200, n_jobs=-1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# random.seed(18)\n",
    "rf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "rf_params = {\n",
    "    'n_estimators':[10,30,50,100,200,250],\n",
    "    'criterion': ('gini','entropy'),\n",
    "    'max_depth': [15,20,30,40,60],\n",
    "    'class_weight' : (None,'balanced','balanced_subsample')\n",
    "}\n",
    "gcv_rf = GridSearchCV(cv=4,estimator=rf,param_grid=rf_params,n_jobs=-1,scoring=score,verbose=1)\n",
    "gcv_rf.fit(X,y_enc)\n",
    "# scores = cross_val_score(clf, X, y, cv=5, scoring=score)\n",
    "\n",
    "print gcv_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best RFC\n",
    "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
    "            criterion='gini', max_depth=15, max_features='auto',\n",
    "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=200, n_jobs=-1, oob_score=False, random_state=0,\n",
    "            verbose=0, warm_start=False)\n",
    "            \n",
    "cv=4 <br>\n",
    "0.811905104099 0.0176607853188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811829641971\n"
     ]
    }
   ],
   "source": [
    "print gcv_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811905104099 0.0176607853188\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(gcv_rf.best_estimator_,X,y_enc, cv=4,n_jobs=-1,scoring=score,verbose=1)\n",
    "\n",
    "print scores.mean(),scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 180 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.4s\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   36.0s\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier(bootstrap=False, class_weight='balanced',\n",
      "           criterion='gini', max_depth=60, max_features='auto',\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=250, n_jobs=-1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "etc = ExtraTreesClassifier(n_jobs=-1)\n",
    "etc_params = {\n",
    "    'n_estimators':[10,30,50,100,200,250],\n",
    "    'criterion': ('gini','entropy'),\n",
    "    'max_depth': [15,20,30,40,60],\n",
    "    'class_weight' : (None,'balanced','balanced_subsample'),\n",
    "    \n",
    "}\n",
    "gcv_etc = GridSearchCV(cv=4,estimator=etc,param_grid=rf_params,n_jobs=-1,scoring=score,verbose=1)\n",
    "gcv_etc.fit(X,y_enc)\n",
    "# scores = cross_val_score(clf, X, y, cv=5, scoring=score)\n",
    "\n",
    "print gcv_etc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775486198935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777778749865 0.0137470677549\n"
     ]
    }
   ],
   "source": [
    "print gcv_etc.best_score_\n",
    "scores = cross_val_score(gcv_etc.best_estimator_,X,y_enc, cv=4,n_jobs=-1,scoring=score,verbose=1)\n",
    "\n",
    "print scores.mean(),scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 80 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   23.0s\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.1min\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=5, p=1,\n",
      "           weights='distance')\n"
     ]
    }
   ],
   "source": [
    "knn = KNN(n_jobs=-1)\n",
    "knn_params = {\n",
    "    'n_neighbors': [5,10,25,50,100],\n",
    "    'weights': ['uniform','distance'],\n",
    "    'algorithm': ('auto', 'ball_tree', 'kd_tree', 'brute'),\n",
    "    'p':[1,2]\n",
    "}\n",
    "gcv_knn = GridSearchCV(cv=4,estimator=knn,param_grid=knn_params,n_jobs=-1,scoring=score,verbose=1)\n",
    "gcv_knn.fit(X,y_enc)\n",
    "# scores = cross_val_score(clf, X, y, cv=5, scoring=score)\n",
    "\n",
    "print gcv_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.669801705702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66977957859 0.0151012433588\n"
     ]
    }
   ],
   "source": [
    "print gcv_knn.best_score_\n",
    "scores = cross_val_score(gcv_knn.best_estimator_,X,y_enc, cv=4,n_jobs=-1,scoring=score,verbose=1)\n",
    "\n",
    "print scores.mean(),scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "1) f1_score :  0.795271667071\n",
      "2) f1_score :  0.851374047154\n",
      "3) f1_score :  0.797495437569\n",
      "4) f1_score :  0.774835746723\n",
      "5) f1_score :  0.836501830552\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "print(kf)  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scores = []\n",
    "count =1\n",
    "for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_enc.iloc[train_index], y_enc.iloc[test_index]\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=150, max_depth=10, random_state=0, n_jobs=-1,class_weight=\"balanced_subsample\")\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "#     print y_pred[:,1]\n",
    "    pop_score = f1_score(y_test[199325], y_pred[:,0], average='macro')\n",
    "    center_score = f1_score(y_test[199326], y_pred[:,1], average='macro')\n",
    "    scores.append((pop_score+center_score)/2.0)\n",
    "    print str(count) +\") f1_score : \", scores[-1]\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average f-1 score is  0.811095745814\n"
     ]
    }
   ],
   "source": [
    "print \"The average f-1 score is \",sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"indices.pkl\", 'rb') as in_file:\n",
    "    indices = pkl.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"X_train_reduced.pkl\", 'rb') as in_file:\n",
    "    X = pkl.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"y.pkl\", 'rb') as in_file:\n",
    "    y = pkl.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 10000)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Multioutput target data is not supported with label binarization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-c4b8fc996b7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                    )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/neural_network/multilayer_perceptron.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    971\u001b[0m         \"\"\"\n\u001b[1;32m    972\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[0;32m--> 973\u001b[0;31m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/neural_network/multilayer_perceptron.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    329\u001b[0m                              hidden_layer_sizes)\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/neural_network/multilayer_perceptron.pyc\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_type_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'multioutput'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_type_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             raise ValueError(\"Multioutput target data is not supported with \"\n\u001b[0m\u001b[1;32m    279\u001b[0m                              \"label binarization\")\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Multioutput target data is not supported with label binarization"
     ]
    }
   ],
   "source": [
    "## Performing 5 fold cross validation on MLP Classifier\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "print(kf)  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scores = []\n",
    "count =1\n",
    "for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(256, 128), activation='logistic', #solver='lbfgs', #learning_rate='adaptive',\n",
    "                    verbose=False, tol=1e-5 ,max_iter=500, learning_rate_init=0.005\n",
    "#                     warm_start = True\n",
    "                   )\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    print count,\") f1_score : \", scores[-1]\n",
    "    count+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average f-1 score is  0.91048192588\n"
     ]
    }
   ],
   "source": [
    "print \"The average f-1 score is \",sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Future Use\n",
    "\n",
    "Using information from equivalence classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_names = utilities.get_folder_names(\"./train/\")\n",
    "\n",
    "# master_set = set()\n",
    "# all_eq_c = {}\n",
    "# count = 0\n",
    "# for f in folder_names:\n",
    "#     with open(\"./train/\" + f +\"/bias/aux_info/eq_classes.txt\") as eq_file:\n",
    "#         eq_c = eq_file.read()\n",
    "#     eq_c = eq_c.strip()\n",
    "#     eq_c = eq_c.split(\"\\r\\n\")\n",
    "#     eq_c = eq_c[199326:]\n",
    "#     eq_c = np.array(eq_c)\n",
    "# #     print eq_c[0]\n",
    "#     cur_eq_c = {}\n",
    "    \n",
    "#     try:\n",
    "\n",
    "#         for i in range(len(eq_c)):\n",
    "#             e = eq_c[i].split('\\t')\n",
    "#             key = int(''.join(e[1:-1]))\n",
    "# #             for i in range(len(e[:-1])):\n",
    "# #                 e[i] = int(''.join()e[i])\n",
    "#             cur_eq_c[key] = int(e[-1])\n",
    "#             master_set.add(key)\n",
    "#     except Exception as err:\n",
    "#         print err\n",
    "#         print f,i\n",
    "    \n",
    "#     all_eq_c[f] = cur_eq_c\n",
    "#     count+=1\n",
    "#     print count\n",
    "#     gc.collect()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(master_set,open('master_set.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_eq_classes.pkl','wb') as f:\n",
    "    pkl.dump(all_eq_c,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5292\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "tot_size = sys.getsizeof(all_eq_c.values())\n",
    "tot_size+= sum(map(sys.getsizeof,all_eq_c.itervalues()))\n",
    "print tot_size/(1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./master_set.pkl', 'rb') as f:\n",
    "    master_set = pkl.load(f)\n",
    "    \n",
    "with open('./all_eq_classes.pkl', 'rb') as f:\n",
    "    all_eq_c = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in all_eq_c.keys():\n",
    "    with open('./eq_classes/'+k+'.pkl', 'wb') as out_file:\n",
    "        pkl.dump(all_eq_c[k], out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "master_set = list(master_set)\n",
    "for i in range(len(master_set)):\n",
    "#     print i\n",
    "    cur = master_set.pop(i)\n",
    "    master_set.insert(i,i)\n",
    "    for folder in all_eq_c:\n",
    "        if cur in all_eq_c[folder]:\n",
    "            all_eq_c[folder][i] = all_eq_c[folder][cur]\n",
    "            del all_eq_c[folder][cur]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_names = utilities.get_folder_names(\"./train/\")\n",
    "train = pd.DataFrame(np.zeros((len(folder_names),len(master_set))),index=folder_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "# for ind in train.index:\n",
    "#     for eq_classes in all_eq_c[ind]:\n",
    "#         train.loc[ind,eq_classes] = all_eq_c[ind][eq_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del master_set\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = pd.Series(list(master_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
